{
  "pr_summary": {
    "title": "adds pre-commit hook to standardize whitespaces, adds EditorConfig to set the indents",
    "author": "nyoungstudios",
    "description": "**Please** add a meaningful description for your change here\r\n\r\nAdds `.editorconfig`\r\nModifies `.pre-commit-config.yaml`\r\nAll other changes where modified by running `pre-commit run -all-files`\r\n\r\nFor more details, keep reading:\r\n\r\nAdds a pre-commit hook to standardize whitespaces, so we don't have stray new lines or missing new line at the end of the file, or stray spaces at the end of a line\r\nAdds an `.editorconfig` file with these same settings. Previously, I found it harder to contribute to the Python codebase since the default Python indent is 4 spaces, but this project uses 2 spaces. So, adding the EditorConfig will let your code editor like VS Code or PyCharm automatically pick up this project's settings. VS Code you need to install the code extension, but PyCharm does have this built in.\r\n\r\nIt seems that we also don't need the `sdks/python/scripts/run_whitespacelint.sh` anymore with this change. But I wasn't quite sure how to remove it from the `build.gradle` yet. And for what it is worth, it is using https://github.com/bendikro/whitespacelint which doesn't look maintained.\r\n\r\nAlso, I wasn't exactly sure how the `.pre-commit-config.yaml` was being run in the GitHub actions or if it was at all since there were comments in the `.pre-commit-config.yaml` referencing to keep the yapf and pylint versions synced elsewhere.\r\n\r\n------------------------\r\n\r\nThank you for your contribution! Follow this checklist to help us incorporate your contribution quickly and easily:\r\n\r\n - [ ] Mention the appropriate issue in your description (for example: `addresses #123`), if applicable. This will automatically add a link to the pull request in the issue. If you would like the issue to automatically close on merging the pull request, comment `fixes #<ISSUE NUMBER>` instead.\r\n - [ ] Update `CHANGES.md` with noteworthy changes.\r\n - [ ] If this contribution is large, please file an Apache [Individual Contributor License Agreement](https://www.apache.org/licenses/icla.pdf).\r\n\r\nSee the [Contributor Guide](https://beam.apache.org/contribute) for more tips on [how to make review process smoother](https://github.com/apache/beam/blob/master/CONTRIBUTING.md#make-the-reviewers-job-easier).\r\n\r\nTo check the build health, please visit [https://github.com/apache/beam/blob/master/.test-infra/BUILD_STATUS.md](https://github.com/apache/beam/blob/master/.test-infra/BUILD_STATUS.md)\r\n\r\nGitHub Actions Tests Status (on master branch)\r\n------------------------------------------------------------------------------------------------\r\n[![Build python source distribution and wheels](https://github.com/apache/beam/actions/workflows/build_wheels.yml/badge.svg?event=schedule&&?branch=master)](https://github.com/apache/beam/actions?query=workflow%3A%22Build+python+source+distribution+and+wheels%22+branch%3Amaster+event%3Aschedule)\r\n[![Python tests](https://github.com/apache/beam/actions/workflows/python_tests.yml/badge.svg?event=schedule&&?branch=master)](https://github.com/apache/beam/actions?query=workflow%3A%22Python+Tests%22+branch%3Amaster+event%3Aschedule)\r\n[![Java tests](https://github.com/apache/beam/actions/workflows/java_tests.yml/badge.svg?event=schedule&&?branch=master)](https://github.com/apache/beam/actions?query=workflow%3A%22Java+Tests%22+branch%3Amaster+event%3Aschedule)\r\n[![Go tests](https://github.com/apache/beam/actions/workflows/go_tests.yml/badge.svg?event=schedule&&?branch=master)](https://github.com/apache/beam/actions?query=workflow%3A%22Go+tests%22+branch%3Amaster+event%3Aschedule)\r\n\r\nSee [CI.md](https://github.com/apache/beam/blob/master/CI.md) for more information about GitHub Actions CI or the [workflows README](https://github.com/apache/beam/blob/master/.github/workflows/README.md) to see a list of phrases to trigger workflows.\r\n",
    "url": "https://github.com/apache/beam/pull/35564"
  },
  "selected_commits": [
    {
      "sha": "2f6d47d48ab64b3a43e170d32dc3953000223614",
      "short_sha": "2f6d47d",
      "message": "adds editorconfig and pre-commit config",
      "author_name": "Nathaniel Young",
      "date": "2025-07-17T00:56:22+00:00",
      "url": "https://github.com/apache/beam/commit/2f6d47d48ab64b3a43e170d32dc3953000223614"
    },
    {
      "sha": "0029f5f18b933959ca3223cfb8641f2a7430b322",
      "short_sha": "0029f5f",
      "message": "applies pre-commit changes",
      "author_name": "Nathaniel Young",
      "date": "2025-07-17T00:59:53+00:00",
      "url": "https://github.com/apache/beam/commit/0029f5f18b933959ca3223cfb8641f2a7430b322"
    }
  ],
  "changes": {
    "ai_summary": "**Overview**: This pull request introduces an `.editorconfig` file to standardize whitespace and indentation across the project, and configures a pre-commit hook to enforce these standards. It also includes updates to various GitHub Actions workflows and related configurations.\n\n**Key Changes**:\n* Added `.editorconfig` file to define coding style (indentation, whitespace, charset, etc.).\n* Configured `.pre-commit-config.yaml` to use a pre-commit hook for whitespace standardization.\n* Modified multiple files by running `pre-commit run --all-files` to apply the new whitespace rules.\n* Updated various GitHub Actions workflows, including changes to test configurations, resource cleanup, and dependency management.\n* Modified various test configurations and arguments for Java, Python, and Go SDKs.\n* Updated Kubernetes deployment configurations for SingleStore and InfluxDB.\n* Added configurations for publishing SDK docker images to Docker Hub.\n\n**Impact**:\n* Introduces consistent code formatting across the project, improving readability and maintainability.\n* May require developers to install the EditorConfig extension in their IDE for automatic style enforcement.\n* Updates to GitHub Actions workflows may affect CI/CD processes, potentially altering test execution and resource management.\n* Changes to test configurations and arguments may impact test results and performance benchmarks.\n",
    "non_text_files": [],
    "raw_diff": "@@ -0,0 +1,30 @@\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+# http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# EditorConfig is awesome: https://EditorConfig.org\n+\n+# top-most EditorConfig file\n+root = true\n+\n+[*]\n+indent_style = space\n+indent_size = 2\n+end_of_line = lf\n+charset = utf-8\n+trim_trailing_whitespace = true\n+insert_final_newline = true\n+\n+[*.go]\n+indent_style = tab\n+indent_size = 4\n+\n+[Dockerfile]\n+indent_size = 4\n@@ -42,7 +42,7 @@ code_review:\n \n     # Post PR summary when opened.\n     # Type boolean, default: true.\n-    summary: true \n+    summary: true\n \n     # Post code review on PR open.\n     # Type boolean, default: true.\n@@ -19,4 +19,4 @@ runs:\n     - name: Removing Keyfile\n       if: ${{ always() }}\n       shell: bash\n-      run: rm -f /tmp/gcp_access.json\n\\ No newline at end of file\n+      run: rm -f /tmp/gcp_access.json\n@@ -51,4 +51,3 @@ runs:\n     - name: Installing python SDK\n       shell: bash\n       run: pip install apache_beam-${RELEASE_VER}.tar.gz[gcp]\n-      \n@@ -16,8 +16,8 @@\n # under the License.\n \n \n-#Action used to trigger a failed check re-run within a PR using a comment. Add this action to your workflow with an if condition \n-#to check if the comment is present \n+#Action used to trigger a failed check re-run within a PR using a comment. Add this action to your workflow with an if condition\n+#to check if the comment is present\n #If the check is failed this will trigger it again. If its not failed a new instance of workflow will run which will not show in the status box or checks tab in the PR and can be found in the actions tab https://github.com/apache/beam/actions\n \n name: \"Rerun Job Action\"\n@@ -45,17 +45,17 @@ runs:\n   steps:\n   - name: Get Last Commit SHA\n     shell: bash\n-    run: | \n+    run: |\n       URL=${{inputs.pull_request_url}}/commits\n       PRSHA=$(curl  \\\n       -H 'Authorization: Bearer ${{inputs.github_token}}' \\\n       -H \"Accept: application/vnd.github+json\" \\\n       -H \"X-GitHub-Api-Version: 2022-11-28\" \\\n-      -s $URL  | jq -r '.[-1].sha' ) \n+      -s $URL  | jq -r '.[-1].sha' )\n       echo prsha=$PRSHA >> $GITHUB_ENV\n   - name: Get Status and Conclusion for PR Job\n     shell: bash\n-    run: | \n+    run: |\n       JOB=\"${{inputs.github_job}}\"\n       QUERY_JOB=${JOB// /+}\n       URL=\"${{github.api_url}}/repos/${{inputs.github_repository}}/commits/${{env.prsha}}/check-runs?check_name=$QUERY_JOB\"\n@@ -73,7 +73,7 @@ runs:\n       echo status=$STATUS >> $GITHUB_ENV\n       echo conclusion=$CONCLUSION >> $GITHUB_ENV\n       echo check_suite_id=$CHECK_SUITE_ID >> $GITHUB_ENV\n- \n+\n \n   - name: Disable Rerun for Success or Skipped\n     if: ${{(env.status == 'completed' && (env.conclusion == 'success' || env.conclusion == 'skipped')) || env.skip == 'true'}}\n@@ -83,7 +83,7 @@ runs:\n   - name: Get Run ID\n     if: ${{env.rerun != 'false' }}\n     shell: bash\n-    run: | \n+    run: |\n       URL=\"${{github.api_url}}/repos/${{inputs.github_repository}}/actions/runs?check_suite_id=${{env.check_suite_id}}\"\n       RUN_ID=$(curl  \\\n       -H 'Authorization: Bearer ${{inputs.github_token}}' \\\n@@ -94,7 +94,7 @@ runs:\n   - name: Get Job ID\n     if: ${{env.rerun != 'false' }}\n     shell: bash\n-    run: | \n+    run: |\n       URL=\"${{github.api_url}}/repos/${{inputs.github_repository}}/actions/runs/${{env.run_id}}/jobs\"\n       JOB_ID=$(curl  \\\n       -H 'Authorization: Bearer ${{inputs.github_token}}' \\\n@@ -105,13 +105,13 @@ runs:\n   - name: Trigger Re-run\n     if: ${{env.rerun != 'false' }}\n     shell: bash\n-    run: | \n+    run: |\n       URL=\"${{github.api_url}}/repos/${{inputs.github_repository}}/actions/jobs/${{env.job_id}}/rerun\"\n       curl -X POST \\\n       -H 'Authorization: Bearer ${{inputs.github_token}}' \\\n       -H \"Accept: application/vnd.github+json\" \\\n       -H \"X-GitHub-Api-Version: 2022-11-28\" \\\n-      -s $URL \n+      -s $URL\n   - name: Install GH Cli\n     if: ${{env.rerun != 'false' }}\n     shell: bash\n@@ -126,4 +126,4 @@ runs:\n       gh run cancel ${{ inputs.github_current_run_id }}\n       gh run watch ${{ inputs.github_current_run_id }}\n     env:\n-      GITHUB_TOKEN: ${{ inputs.github_token }}\n\\ No newline at end of file\n+      GITHUB_TOKEN: ${{ inputs.github_token }}\n@@ -64,7 +64,7 @@ runs:\n       with:\n         github_token: ${{ inputs.github_token }}\n         github_job: ${{ inputs.github_job || github.job }}\n-        github_repository: ${{ github.repository }}     \n+        github_repository: ${{ github.repository }}\n         github_current_run_id: ${{ github.run_id }}\n         pull_request_url: ${{ github.event.issue.pull_request.url }}\n     ## Used for jobs that spawn docker containers and need to mount gcloud config directory\n@@ -28,4 +28,4 @@ runs:\n       shell: bash\n       run: |\n         JSON=$(cat ./.github/actions/setup-default-test-properties/test-properties.json)\n-        echo \"test-properties=$(echo $JSON)\" >> $GITHUB_OUTPUT\n\\ No newline at end of file\n+        echo \"test-properties=$(echo $JSON)\" >> $GITHUB_OUTPUT\n@@ -16,8 +16,8 @@\n # under the License.\n \n \n-#Action used to trigger a failed check re-run within a PR using a comment. Add this action to your workflow with an if condition \n-#to check if the comment is present \n+#Action used to trigger a failed check re-run within a PR using a comment. Add this action to your workflow with an if condition\n+#to check if the comment is present\n #If the check is failed this will trigger it again. If its not failed a new instance of workflow will run which will not show in the status box or checks tab in the PR and can be found in the actions tab https://github.com/apache/beam/actions\n \n name: \"Setup Kuberenetes Access\"\n@@ -44,7 +44,7 @@ runs:\n   steps:\n   - name: Check if inputs were provided\n     shell: bash\n-    run: | \n+    run: |\n       if [ -z \"${{ inputs.k8s_namespace }}\" ]; then\n         echo \"Kubernetes namespace not provided\"\n         exit 1\n@@ -61,7 +61,7 @@ runs:\n       gcloud container clusters get-credentials ${{ inputs.cluster_name }} --zone ${{ inputs.cluster_zone }} --project apache-beam-testing\n   - name: Create namespace\n     shell: bash\n-    run: | \n+    run: |\n       kubectl create namespace ${{ steps.replace_namespace.outputs.TEST_NAMESPACE }}\n   - name: Set default namespace\n     shell: bash\n@@ -38,14 +38,14 @@ runs:\n   steps:\n     - name: Check if test-type was provided\n       shell: bash\n-      run: | \n+      run: |\n         if [ -z \"${{ inputs.test-type }}\" ]; then\n           echo \"Test type was not provided\"\n           exit 1\n         fi\n     - name: Check if test-language was provided\n       shell: bash\n-      run: | \n+      run: |\n         if [ -z \"${{ inputs.test-language }}\" ]; then\n           echo \"Test language was not provided\"\n           exit 1\n@@ -67,7 +67,7 @@ io:  [\"sdks/go/pkg/beam/io/**/*\", \"sdks/java/io/**/*\", \"sdks/python/apache_beam/\n \"mqtt\":  [\"sdks/java/io/mqtt/**/*\"]\n \"parquet\":  [\"sdks/java/io/parquet/**/*\"]\n \"rabbitmq\":  [\"sdks/java/io/rabbitmq/**/*\"]\n-\"redis\":  [\"sdks/java/io/redis/**/*\"] \n+\"redis\":  [\"sdks/java/io/redis/**/*\"]\n \"solr\":  [\"sdks/java/io/solr/**/*\"]\n \"spanner\": [\"sdks/go/pkg/beam/io/spannerio/**/*\", \"sdks/python/apache_beam/io/gcp/spanner.py\", \"sdks/python/apache_beam/io/gcp/experimental/spannerio.py\", \"sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/spanner/**/*\"]\n \"bigtable\": [\"sdks/go/pkg/beam/io/bigtableio/**/*\", \"sdks/go/pkg/beam/io/xlang/bigtableio/**/*\", \"sdks/python/apache_beam/io/gcp/bigtableio.py\", \"sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigtable/**/*\"]\n@@ -76,7 +76,7 @@ io:  [\"sdks/go/pkg/beam/io/**/*\", \"sdks/java/io/**/*\", \"sdks/python/apache_beam/\n \"thrift\": [\"sdks/java/io/thrift/**/*\"]\n \"tika\":  [\"sdks/java/io/tika/**/*\"]\n \"xml\":  [\"sdks/java/io/xml/**/*\"]\n- \n+\n # Runners\n \"runners\": [\"runners/**/*\", \"sdks/go/pkg/beam/runners/**/*\", \"sdks/python/apache_beam/runners/**/*\", \"sdks/typescript/src/apache_beam/runners/**/*\"]\n \"core\": [\"runners/core-java/**/*\"]\n@@ -77,4 +77,4 @@ task check {\n \n task preCommit {\n   dependsOn check\n-}\n\\ No newline at end of file\n+}\n@@ -29,23 +29,23 @@ coverage:\n   status:\n     project:\n       python:\n-        flags: \n+        flags:\n           - python\n         target: auto\n         threshold: 5%\n         base: auto\n         paths:\n           - \"sdks/python\"\n       go:\n-        flags: \n+        flags:\n           - go\n         target: auto\n         threshold: 5%\n         base: auto\n         paths:\n           - \"sdks/go/pkg\"\n       java:\n-        flags: \n+        flags:\n           - java\n         target: auto\n         threshold: 5%\n@@ -63,7 +63,7 @@ parsers:\n \n fixes:\n   - \"apache_beam/::sdks/python/apache_beam/\"\n-  \n+\n github_checks:\n   annotations: false\n \n@@ -118,4 +118,4 @@ Depending on the termination event, sometimes the removal script for offline run\n This was implemented using a [GCP Cloud Function](https://console.cloud.google.com/functions/details/us-central1/remove-self-hosted-runners-group?env=gen1&project=apache-beam-testing&tab=source) [[code]](./helper-functions/cloud-functions/removeOfflineRunners) subscribed to a [Pub/Sub](https://console.cloud.google.com/cloudpubsub/topic/detail/remove-runners?referrer=search&project=apache-beam-testing) topic, the topic is triggered through a [Cloud Scheduler](https://console.cloud.google.com/cloudscheduler/jobs/edit/us-central1/runners-clean-up-schedule?project=apache-beam-testing) that is executed once per day, the function consumes a [GitHub API](https://docs.github.com/en/rest/reference/actions#delete-a-self-hosted-runner-from-an-organization) to delete offline self-hosted runners from the organization retrieving the token with its service account to secrets manager.\n \n \n-![Delete Offline Self-hosted Runners](diagrams/self-hosted-runners-delete-function.png)\n\\ No newline at end of file\n+![Delete Offline Self-hosted Runners](diagrams/self-hosted-runners-delete-function.png)\n@@ -99,4 +99,3 @@ terraform apply -var-file=environments/environment_name.env\n # Maintanance\n \n - To access the ARC k8s cluster call the `get_kubeconfig_command` terraform output and run the command\n-\n@@ -29,7 +29,7 @@ spec:\n       dockerMTU: 1460\n       %{~ if selector == true  ~}\n       nodeSelector:\n-        runner-pool: ${name} \n+        runner-pool: ${name}\n       %{~ endif ~}\n       %{~ if taint == true  ~}\n       tolerations:\n@@ -61,4 +61,3 @@ spec:\n           memory: ${limits.memory}\n       %{~ endif ~}\n       %{~ endif ~}\n-\n@@ -21,7 +21,7 @@ project_id = \"apache-beam-testing\"\n region = \"us-central1\"\n zone = \"us-central1-b\"\n environment = \"beam-prod\"\n-ingress_domain = \"action.beam.apache.org\" \n+ingress_domain = \"action.beam.apache.org\"\n organization = \"apache\"\n repository = \"beam\"\n github_app_id_secret_name = \"gh-app_id\"\n@@ -78,7 +78,7 @@ resource \"google_container_node_pool\" \"additional_runner_pools\" {\n     labels = {\n       \"runner-pool\" = each.value.name\n     }\n-   \n+\n     dynamic \"taint\" {\n       for_each = each.value.enable_taint == true ? [1] : []\n       content {\n@@ -103,4 +103,4 @@ data \"google_compute_global_address\" \"actions-runner-ip\" {\n \n data google_service_account \"service_account\" {\n   account_id = var.service_account_id\n-}\n\\ No newline at end of file\n+}\n@@ -22,7 +22,7 @@ resource \"helm_release\" \"cert-manager\" {\n   create_namespace = true\n   repository = \"https://charts.jetstack.io\"\n   chart      = \"cert-manager\"\n-  \n+\n   atomic = \"true\"\n   timeout = 100\n \n@@ -19,4 +19,4 @@\n data \"google_client_config\" \"provider\" {}\n \n data \"google_client_openid_userinfo\" \"provider_identity\" {\n-}\n\\ No newline at end of file\n+}\n@@ -33,4 +33,4 @@ gcloud auth configure-docker us-central1-docker.pkg.dev\n ```\n docker push us-central1-docker.pkg.dev/apache-beam-testing/beam-github-actions/beam-arc-runner:$RUNNER_IMAGE_TAG\n docker push us-central1-docker.pkg.dev/apache-beam-testing/beam-github-actions/beam-arc-runner:$(git rev-parse --short HEAD)\n-```\n\\ No newline at end of file\n+```\n@@ -36,4 +36,4 @@ locals {\n             \"githubWebhookServer.ingress.annotations.networking\\\\.gke\\\\.io/managed-certificates\" = \"managed-cert\"\n             \"githubWebhookServer.ingress.annotations.kubernetes\\\\.io/ingress\\\\.class\" = \"gce\"\n         }\n-}\n\\ No newline at end of file\n+}\n@@ -29,4 +29,3 @@ output \"ingress_ip\" {\n output \"get_kubeconfig_command\" {\n     value = \"gcloud container clusters get-credentials ${google_container_cluster.actions-runner-gke.name} --region ${var.zone} --project ${var.project_id}\"\n }\n-  \n@@ -65,5 +65,5 @@ provider \"github\" {\n     installation_id = data.google_secret_manager_secret_version.github_app_install_id.secret_data\n   }\n   owner = var.organization\n-  \n-}\n\\ No newline at end of file\n+\n+}\n@@ -27,4 +27,4 @@ data \"google_secret_manager_secret_version\" \"github_app_install_id\" {\n data \"google_secret_manager_secret_version\" \"github_private_key\" {\n   project = var.project_id\n   secret = var.github_private_key_secret_name\n-}\n\\ No newline at end of file\n+}\n@@ -19,7 +19,7 @@\n \n variable \"project_id\" {\n     description = \"Google Project ID to use for deployment\"\n-    \n+\n }\n variable \"region\" {\n     description = \"Google Region to use for deployment\"\n@@ -66,10 +66,10 @@ variable \"existing_ip_name\" {\n     description = \"Name of existing IP to use for ingress\"\n     default = \"\"\n }\n-variable \"subnetwork_cidr_range\" { \n+variable \"subnetwork_cidr_range\" {\n     description = \"CIDR range for subnetwork\"\n     default = \"10.128.0.0/20\"\n-  \n+\n }\n variable \"service_account_id\" {\n     description = \"ID of service account to use for deployment. This can be Name, full Email or Fully Qualified Path\"\n@@ -98,7 +98,7 @@ variable \"main_runner\" {\n         cpu = string\n         memory = string\n         }), { cpu = \"500m\",\n-              memory = \"500Mi\" \n+              memory = \"500Mi\"\n         })\n       limits = optional(object({\n         cpu = optional(string)\n@@ -127,7 +127,7 @@ variable \"additional_runner_pools\" {\n         cpu = string\n         memory = string\n         }), { cpu = \"500m\",\n-              memory = \"500Mi\" \n+              memory = \"500Mi\"\n         })\n       limits = optional(object({\n         cpu = optional(string)\n@@ -138,4 +138,4 @@ variable \"additional_runner_pools\" {\n         })\n     }))\n     default = []\n-}\n\\ No newline at end of file\n+}\n@@ -27,5 +27,5 @@ resource \"github_repository_webhook\" \"webhook\" {\n     insecure_ssl = false\n   }\n   active       = true\n-  events       = [\"workflow_job\"]  \n-}\n\\ No newline at end of file\n+  events       = [\"workflow_job\"]\n+}\n@@ -36,4 +36,4 @@ Function implemented to retrieve the GitHub App token for register a self-hosted\n #####  monitorRunnersStatus\n Function implemented to get the status of the self-hosted runners. It's used in the [monitor_self_hosted_runners](../../workflows/monitor_self_hosted_runners.yml) workflow.\n #### removeOfflineRunners\n-Function implemented to delete the unused self-hosted runners. Please refer to this [README](../self-hosted-linux/README.md) for more details.\n\\ No newline at end of file\n+Function implemented to delete the unused self-hosted runners. Please refer to this [README](../self-hosted-linux/README.md) for more details.\n@@ -5,4 +5,4 @@ CLIENT_ID=\n PEM_KEY=\n CLIENT_NAME=\n ORG=\n-PROJECT_ID=\n\\ No newline at end of file\n+PROJECT_ID=\n@@ -52,7 +52,7 @@ async function monitorRunnerStatus() {\n             org: process.env.ORG\n             },\n         )\n-        \n+\n         //Filtering BEAM runners\n         let beamRunners = runners.filter(runner => {\n             return runner.labels.find(label => label.name == \"beam\")\n@@ -11,4 +11,4 @@\n     \"@octokit/auth-app\": \"^3.6.1\",\n     \"octokit\": \"^1.7.1\"\n   }\n-}\n\\ No newline at end of file\n+}\n@@ -11,4 +11,4 @@\n     \"@octokit/auth-app\": \"^3.6.1\",\n     \"octokit\": \"^1.7.1\"\n   }\n-}\n\\ No newline at end of file\n+}\n@@ -97,4 +97,4 @@ For the current implementation we are using Google Kubernetes Engine (GKE) as a\n \n * In case you would like to delete all the Kubernetes resources, run the `delete-k8s-deployment.sh` script with its corresponding namespace value.\n \n-`./delete-k8s-deployment.sh $NAMESPACE`\n\\ No newline at end of file\n+`./delete-k8s-deployment.sh $NAMESPACE`\n@@ -4,4 +4,4 @@ CLOUD_FUNCTION_NAME=\n ORG_RUNNER_GROUP=\n ORG_NAME=\n GCP_REGION=\n-GCP_PROJECT_ID=\n\\ No newline at end of file\n+GCP_PROJECT_ID=\n@@ -40,4 +40,4 @@ This folder contains the required resources to deploy the GitHub Actions self-ho\n \n **Be sure that you are using a service account that has permissions to invoke cloud functions.**\n \n-Now that the instance template is ready you can use it to either run it independently for an individual runner or create an instance group for a set of runners.\n\\ No newline at end of file\n+Now that the instance template is ready you can use it to either run it independently for an individual runner or create an instance group for a set of runners.\n@@ -20,4 +20,4 @@ Write-Output \"removingRunner\"\n Set-Location C:/actionsDir\n \n $token=[System.Environment]::GetEnvironmentVariable('GITHUB_TOKEN','machine')\n-./config.cmd remove --token $token\n\\ No newline at end of file\n+./config.cmd remove --token $token\n@@ -46,4 +46,4 @@ $hostname= \"windows-runner-\"+[guid]::NewGuid()\n \n ./config.cmd --name $hostname --token $RUNNER_TOKEN --url https://github.com/$ORG_NAME --work _work --unattended --replace --labels windows,beam,windows-server-2019 --runnergroup $ORG_RUNNER_GROUP\n \n-./run.cmd\n\\ No newline at end of file\n+./run.cmd\n@@ -1,4 +1,4 @@\n {\n   \"comment\": \"Modify this file in a trivial way to cause this test suite to run\",\n   \"modification\": 1\n-}\n\\ No newline at end of file\n+}\n@@ -1 +1 @@\n-{\"revision\":  1}\n\\ No newline at end of file\n+{\"revision\":  1}\n@@ -1,4 +1,4 @@\n {\n   \"comment\": \"Modify this file in a trivial way to cause this test suite to run\",\n   \"modification\": 4\n-}\n\\ No newline at end of file\n+}\n@@ -2,4 +2,3 @@\n   \"comment\": \"Modify this file in a trivial way to cause this test suite to run.\",\n   \"modification\": 2\n }\n-\n@@ -1,4 +1,4 @@\n {\n     \"comment\": \"Modify this file in a trivial way to cause this test suite to run\",\n     \"modification\": 2\n-  }\n\\ No newline at end of file\n+  }\n@@ -1,4 +1,4 @@\n {\n     \"comment\": \"Modify this file in a trivial way to cause this test suite to run\",\n     \"modification\": 4\n-}\n\\ No newline at end of file\n+}\n@@ -1,3 +1,3 @@\n {\n   \"modification\": 1\n-}\n\\ No newline at end of file\n+}\n@@ -1 +1 @@\n-{\"modification\":  1}\n\\ No newline at end of file\n+{\"modification\":  1}\n@@ -75,4 +75,4 @@ jobs:\n       - name: Run IcebergIO Integration Test\n         uses: ./.github/actions/gradle-command-self-hosted-action\n         with:\n-          gradle-command: :sdks:java:io:iceberg:integrationTest --info\n\\ No newline at end of file\n+          gradle-command: :sdks:java:io:iceberg:integrationTest --info\n@@ -75,4 +75,4 @@ jobs:\n       - name: Run IcebergIO Integration Tests on Dataflow\n         uses: ./.github/actions/gradle-command-self-hosted-action\n         with:\n-          gradle-command: :sdks:java:io:iceberg:dataflowIntegrationTest --info\n\\ No newline at end of file\n+          gradle-command: :sdks:java:io:iceberg:dataflowIntegrationTest --info\n@@ -78,4 +78,4 @@ jobs:\n           gradle-command: :sdks:java:io:iceberg:dataflowIntegrationTest\n           arguments: |\n             --info \\\n-            -PenableManagedTransforms\n\\ No newline at end of file\n+            -PenableManagedTransforms\n@@ -75,4 +75,4 @@ jobs:\n       - name: Run IcebergIO Performance Test\n         uses: ./.github/actions/gradle-command-self-hosted-action\n         with:\n-          gradle-command: :sdks:java:io:iceberg:loadTest\n\\ No newline at end of file\n+          gradle-command: :sdks:java:io:iceberg:loadTest\n@@ -54,7 +54,7 @@ jobs:\n     runs-on: [self-hosted, ubuntu-20.04, main]\n     timeout-minutes: 120\n     strategy:\n-      matrix: \n+      matrix:\n         job_name: [beam_CancelStaleDataflowJobs]\n         job_phrase: [Run Cancel Stale Dataflow Jobs]\n     if: |\n@@ -77,4 +77,3 @@ jobs:\n         uses: ./.github/actions/gradle-command-self-hosted-action\n         with:\n           gradle-command: :beam-test-tools:cancelStaleDataflowJobs\n-\n@@ -58,4 +58,4 @@ jobs:\n       - uses: actions/checkout@v4\n       - name: Delete leaked resources for all the jobs that generates flink clusters\n         run: |\n-          cd ${{ github.workspace }}/.test-infra/dataproc; ./cleanup.sh -xe\n\\ No newline at end of file\n+          cd ${{ github.workspace }}/.test-infra/dataproc; ./cleanup.sh -xe\n@@ -54,7 +54,7 @@ jobs:\n     runs-on: [self-hosted, ubuntu-20.04, main]\n     timeout-minutes: 100\n     strategy:\n-      matrix: \n+      matrix:\n         job_name: [beam_CleanUpGCPResources]\n         job_phrase: [Run Clean GCP Resources]\n     if: |\n@@ -80,4 +80,4 @@ jobs:\n       - name: run cleanup GCP resources\n         uses: ./.github/actions/gradle-command-self-hosted-action\n         with:\n-            gradle-command: :beam-test-tools:cleanupOtherStaleResources\n\\ No newline at end of file\n+            gradle-command: :beam-test-tools:cleanupOtherStaleResources\n@@ -54,7 +54,7 @@ jobs:\n     runs-on: [self-hosted, ubuntu-20.04, main]\n     timeout-minutes: 180\n     strategy:\n-      matrix: \n+      matrix:\n         job_name: [beam_CleanUpPrebuiltSDKImages]\n         job_phrase: [Run Clean Prebuilt Images]\n     if: |\n@@ -80,4 +80,4 @@ jobs:\n       - name: run remove stale sdk container images\n         uses: ./.github/actions/gradle-command-self-hosted-action\n         with:\n-          gradle-command: :beam-test-tools:removeStaleSDKContainerImages\n\\ No newline at end of file\n+          gradle-command: :beam-test-tools:removeStaleSDKContainerImages\n@@ -95,4 +95,4 @@ jobs:\n           to: dev@beam.apache.org\n           from: gactions@beam.apache.org\n           body: |\n-            Something went wrong during the automatic credentials rotation for IO-Datastores Cluster, performed at ${{ env.date }}. It may be necessary to check the state of the cluster certificates. For further details refer to the following links:\\n * Failing job: https://github.com/apache/beam/actions/workflows/beam_IODatastoresCredentialsRotation.yml \\n * Job configuration: https://github.com/apache/beam/blob/master/.github/workflows/beam_IODatastoresCredentialsRotation.yml \\n * Cluster URL: https://pantheon.corp.google.com/kubernetes/clusters/details/us-central1-a/io-datastores/details?mods=dataflow_dev&project=apache-beam-testing\n\\ No newline at end of file\n+            Something went wrong during the automatic credentials rotation for IO-Datastores Cluster, performed at ${{ env.date }}. It may be necessary to check the state of the cluster certificates. For further details refer to the following links:\\n * Failing job: https://github.com/apache/beam/actions/workflows/beam_IODatastoresCredentialsRotation.yml \\n * Job configuration: https://github.com/apache/beam/blob/master/.github/workflows/beam_IODatastoresCredentialsRotation.yml \\n * Cluster URL: https://pantheon.corp.google.com/kubernetes/clusters/details/us-central1-a/io-datastores/details?mods=dataflow_dev&project=apache-beam-testing\n@@ -165,4 +165,4 @@ jobs:\n             -Prunner=DataflowRunner \\\n             -PpythonVersion=3.10 \\\n             -PloadTest.requirementsTxtFile=apache_beam/ml/inference/torch_tests_requirements.txt \\\n-            '-PloadTest.args=${{ env.beam_Inference_Python_Benchmarks_Dataflow_test_arguments_5 }} --job_name=benchmark-tests-pytorch-imagenet-python-gpu-${{env.NOW_UTC}} --output=gs://temp-storage-for-end-to-end-tests/torch/result_resnet152_gpu-${{env.NOW_UTC}}.txt'\n\\ No newline at end of file\n+            '-PloadTest.args=${{ env.beam_Inference_Python_Benchmarks_Dataflow_test_arguments_5 }} --job_name=benchmark-tests-pytorch-imagenet-python-gpu-${{env.NOW_UTC}} --output=gs://temp-storage-for-end-to-end-tests/torch/result_resnet152_gpu-${{env.NOW_UTC}}.txt'\n@@ -72,4 +72,4 @@ jobs:\n       - name: run the Java JMH micro-benchmark core suite\n         uses: ./.github/actions/gradle-command-self-hosted-action\n         with:\n-          gradle-command: :sdks:java:core:jmh:jmh\n\\ No newline at end of file\n+          gradle-command: :sdks:java:core:jmh:jmh\n@@ -104,4 +104,4 @@ jobs:\n           arguments: |\n             -PloadTest.mainClass=org.apache.beam.sdk.loadtests.CombineLoadTest \\\n             -Prunner=:runners:google-cloud-dataflow-java \\\n-            '-PloadTest.args=${{ env.beam_Java_LoadTests_Combine_Smoke_test_arguments_3 }}'\n\\ No newline at end of file\n+            '-PloadTest.args=${{ env.beam_Java_LoadTests_Combine_Smoke_test_arguments_3 }}'\n@@ -114,4 +114,4 @@ jobs:\n           arguments: |\n             -PloadTest.mainClass=cogbk \\\n             -Prunner=DataflowRunner \\\n-            '-PloadTest.args=${{ env.beam_LoadTests_Go_CoGBK_Dataflow_Batch_test_arguments_4 }}'\n\\ No newline at end of file\n+            '-PloadTest.args=${{ env.beam_LoadTests_Go_CoGBK_Dataflow_Batch_test_arguments_4 }}'\n@@ -128,4 +128,4 @@ jobs:\n       - name: Teardown Flink\n         if: always()\n         run: |\n-          ${{ github.workspace }}/.test-infra/dataproc/flink_cluster.sh delete\n\\ No newline at end of file\n+          ${{ github.workspace }}/.test-infra/dataproc/flink_cluster.sh delete\n@@ -106,4 +106,4 @@ jobs:\n           arguments: |\n             -PloadTest.mainClass=combine \\\n             -Prunner=DataflowRunner \\\n-            '-PloadTest.args=${{ env.beam_LoadTests_Go_Combine_Dataflow_Batch_test_arguments_3 }} --job_name=load-tests-go-dataflow-batch-combine-3-${{env.NOW_UTC}}'\n\\ No newline at end of file\n+            '-PloadTest.args=${{ env.beam_LoadTests_Go_Combine_Dataflow_Batch_test_arguments_3 }} --job_name=load-tests-go-dataflow-batch-combine-3-${{env.NOW_UTC}}'\n@@ -131,4 +131,4 @@ jobs:\n       - name: Teardown Flink\n         if: always()\n         run: |\n-          ${{ github.workspace }}/.test-infra/dataproc/flink_cluster.sh delete\n\\ No newline at end of file\n+          ${{ github.workspace }}/.test-infra/dataproc/flink_cluster.sh delete\n@@ -142,4 +142,4 @@ jobs:\n           arguments: |\n             -PloadTest.mainClass=group_by_key \\\n             -Prunner=DataflowRunner \\\n-            '-PloadTest.args=${{ env.beam_LoadTests_Go_GBK_Dataflow_Batch_test_arguments_7 }} --job_name=load-tests-go-dataflow-batch-gbk-7-${{env.NOW_UTC}}'\n\\ No newline at end of file\n+            '-PloadTest.args=${{ env.beam_LoadTests_Go_GBK_Dataflow_Batch_test_arguments_7 }} --job_name=load-tests-go-dataflow-batch-gbk-7-${{env.NOW_UTC}}'\n@@ -163,4 +163,4 @@ jobs:\n       - name: Teardown Flink\n         if: always()\n         run: |\n-          ${{ github.workspace }}/.test-infra/dataproc/flink_cluster.sh delete\n\\ No newline at end of file\n+          ${{ github.workspace }}/.test-infra/dataproc/flink_cluster.sh delete\n@@ -114,4 +114,4 @@ jobs:\n           arguments: |\n             -PloadTest.mainClass=pardo \\\n             -Prunner=DataflowRunner \\\n-            '-PloadTest.args=${{ env.beam_LoadTests_Go_ParDo_Dataflow_Batch_test_arguments_4 }}'\n\\ No newline at end of file\n+            '-PloadTest.args=${{ env.beam_LoadTests_Go_ParDo_Dataflow_Batch_test_arguments_4 }}'\n@@ -138,4 +138,4 @@ jobs:\n       - name: Teardown Flink\n         if: always()\n         run: |\n-          ${{ github.workspace }}/.test-infra/dataproc/flink_cluster.sh delete\n\\ No newline at end of file\n+          ${{ github.workspace }}/.test-infra/dataproc/flink_cluster.sh delete\n@@ -96,4 +96,4 @@ jobs:\n           arguments: |\n             -PloadTest.mainClass=sideinput \\\n             -Prunner=DataflowRunner \\\n-            '-PloadTest.args=${{ env.beam_LoadTests_Go_SideInput_Dataflow_Batch_test_arguments_2 }}'\n\\ No newline at end of file\n+            '-PloadTest.args=${{ env.beam_LoadTests_Go_SideInput_Dataflow_Batch_test_arguments_2 }}'\n@@ -118,4 +118,4 @@ jobs:\n       - name: Teardown Flink\n         if: always()\n         run: |\n-          ${{ github.workspace }}/.test-infra/dataproc/flink_cluster.sh delete\n\\ No newline at end of file\n+          ${{ github.workspace }}/.test-infra/dataproc/flink_cluster.sh delete\n@@ -113,4 +113,4 @@ jobs:\n           arguments: |\n             -PloadTest.mainClass=org.apache.beam.sdk.loadtests.CoGroupByKeyLoadTest \\\n             -Prunner=:runners:google-cloud-dataflow-java \\\n-            '-PloadTest.args=${{ env.beam_LoadTests_Java_CoGBK_Dataflow_Batch_test_arguments_4 }} --appName=load_tests_Java_Dataflow_batch_CoGBK_4'\n\\ No newline at end of file\n+            '-PloadTest.args=${{ env.beam_LoadTests_Java_CoGBK_Dataflow_Batch_test_arguments_4 }} --appName=load_tests_Java_Dataflow_batch_CoGBK_4'\n@@ -125,4 +125,4 @@ jobs:\n         if: always()\n         with:\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -87,7 +87,7 @@ jobs:\n             ${{ github.workspace }}/.github/workflows/load-tests-pipeline-options/java_CoGBK_Dataflow_Batch_100b_Multiple_Keys.txt\n             ${{ github.workspace }}/.github/workflows/load-tests-pipeline-options/java_CoGBK_Dataflow_Batch_10kB.txt\n             ${{ github.workspace }}/.github/workflows/load-tests-pipeline-options/java_CoGBK_Dataflow_Batch_2MB.txt\n-          arguments: |            \n+          arguments: |\n             --influxTags={\\\"runnerVersion\\\":\\\"v2\\\",\\\"jdk\\\":\\\"java${{ matrix.java_version }}\\\"}\n       # The env variables are created and populated in the test-arguments-action as \"<github.job>_test_arguments_<argument_file_paths_index>\"\n       - name: run CoGBK 2GB 100  byte records - single key\n@@ -129,4 +129,4 @@ jobs:\n             -Pjava${{ matrix.java_version }}Home=$JAVA_HOME_${{ matrix.java_version }}_X64 \\\n             -PloadTest.mainClass=org.apache.beam.sdk.loadtests.CoGroupByKeyLoadTest \\\n             -Prunner=:runners:google-cloud-dataflow-java \\\n-            '-PloadTest.args=${{ env.beam_LoadTests_Java_CoGBK_Dataflow_V2_Batch_JavaVersions_test_arguments_4 }} --appName=load_tests_Java${{ matrix.java_version }}_Dataflow_V2_batch_CoGBK_4'\n\\ No newline at end of file\n+            '-PloadTest.args=${{ env.beam_LoadTests_Java_CoGBK_Dataflow_V2_Batch_JavaVersions_test_arguments_4 }} --appName=load_tests_Java${{ matrix.java_version }}_Dataflow_V2_batch_CoGBK_4'\n@@ -129,4 +129,4 @@ jobs:\n             -Pjava${{ matrix.java_version }}Home=$JAVA_HOME_${{ matrix.java_version }}_X64 \\\n             -PloadTest.mainClass=org.apache.beam.sdk.loadtests.CoGroupByKeyLoadTest \\\n             -Prunner=:runners:google-cloud-dataflow-java \\\n-            '-PloadTest.args=${{ env.beam_LoadTests_Java_CoGBK_Dataflow_V2_Streaming_JavaVersions_test_arguments_4 }} --appName=load_tests_Java${{ matrix.java_version }}_Dataflow_V2_streaming_CoGBK_4'\n\\ No newline at end of file\n+            '-PloadTest.args=${{ env.beam_LoadTests_Java_CoGBK_Dataflow_V2_Streaming_JavaVersions_test_arguments_4 }} --appName=load_tests_Java${{ matrix.java_version }}_Dataflow_V2_streaming_CoGBK_4'\n@@ -113,4 +113,4 @@ jobs:\n           arguments: |\n             -PloadTest.mainClass=org.apache.beam.sdk.loadtests.CoGroupByKeyLoadTest \\\n             -Prunner=:runners:spark:3 \\\n-            '-PloadTest.args=${{ env.beam_LoadTests_Java_CoGBK_SparkStructuredStreaming_Batch_test_arguments_4 }}'\n\\ No newline at end of file\n+            '-PloadTest.args=${{ env.beam_LoadTests_Java_CoGBK_SparkStructuredStreaming_Batch_test_arguments_4 }}'\n@@ -103,4 +103,4 @@ jobs:\n           arguments: |\n             -PloadTest.mainClass=org.apache.beam.sdk.loadtests.CombineLoadTest \\\n             -Prunner=:runners:google-cloud-dataflow-java \\\n-            '-PloadTest.args=${{ env.beam_LoadTests_Java_Combine_Dataflow_Batch_test_arguments_3 }}'\n\\ No newline at end of file\n+            '-PloadTest.args=${{ env.beam_LoadTests_Java_Combine_Dataflow_Batch_test_arguments_3 }}'\n@@ -104,4 +104,4 @@ jobs:\n           arguments: |\n             -PloadTest.mainClass=org.apache.beam.sdk.loadtests.CombineLoadTest \\\n             -Prunner=:runners:google-cloud-dataflow-java \\\n-            '-PloadTest.args=${{ env.beam_LoadTests_Java_Combine_Dataflow_Streaming_test_arguments_3 }}'\n\\ No newline at end of file\n+            '-PloadTest.args=${{ env.beam_LoadTests_Java_Combine_Dataflow_Streaming_test_arguments_3 }}'\n@@ -104,4 +104,4 @@ jobs:\n           arguments: |\n             -PloadTest.mainClass=org.apache.beam.sdk.loadtests.CombineLoadTest \\\n             -Prunner=:runners:spark:3 \\\n-            '-PloadTest.args=${{ env.beam_LoadTests_Java_Combine_SparkStructuredStreaming_Batch_test_arguments_3 }}'\n\\ No newline at end of file\n+            '-PloadTest.args=${{ env.beam_LoadTests_Java_Combine_SparkStructuredStreaming_Batch_test_arguments_3 }}'\n@@ -140,4 +140,4 @@ jobs:\n           arguments: |\n             -PloadTest.mainClass=org.apache.beam.sdk.loadtests.GroupByKeyLoadTest \\\n             -Prunner=:runners:google-cloud-dataflow-java \\\n-            '-PloadTest.args=${{ env.beam_LoadTests_Java_GBK_Dataflow_Batch_test_arguments_7 }}'\n\\ No newline at end of file\n+            '-PloadTest.args=${{ env.beam_LoadTests_Java_GBK_Dataflow_Batch_test_arguments_7 }}'\n@@ -140,4 +140,4 @@ jobs:\n           arguments: |\n             -PloadTest.mainClass=org.apache.beam.sdk.loadtests.GroupByKeyLoadTest \\\n             -Prunner=:runners:google-cloud-dataflow-java \\\n-            '-PloadTest.args=${{ env.beam_LoadTests_Java_GBK_Dataflow_Streaming_test_arguments_7 }}'\n\\ No newline at end of file\n+            '-PloadTest.args=${{ env.beam_LoadTests_Java_GBK_Dataflow_Streaming_test_arguments_7 }}'\n@@ -149,4 +149,4 @@ jobs:\n             -PloadTest.mainClass=org.apache.beam.sdk.loadtests.GroupByKeyLoadTest \\\n             -Prunner=:runners:google-cloud-dataflow-java \\\n             -Prunner.version=V2 \\\n-            '-PloadTest.args=${{ env.beam_LoadTests_Java_GBK_Dataflow_V2_Batch_test_arguments_7 }}'\n\\ No newline at end of file\n+            '-PloadTest.args=${{ env.beam_LoadTests_Java_GBK_Dataflow_V2_Batch_test_arguments_7 }}'\n@@ -165,4 +165,4 @@ jobs:\n             -Prunner.version=V2 \\\n             -PtestJavaVersion=17 \\\n             -Pjava17Home=$JAVA_HOME_17_X64 \\\n-            '-PloadTest.args=${{ env.beam_LoadTests_Java_GBK_Dataflow_V2_Batch_Java17_test_arguments_7 }}'\n\\ No newline at end of file\n+            '-PloadTest.args=${{ env.beam_LoadTests_Java_GBK_Dataflow_V2_Batch_Java17_test_arguments_7 }}'\n@@ -149,4 +149,4 @@ jobs:\n             -PloadTest.mainClass=org.apache.beam.sdk.loadtests.GroupByKeyLoadTest \\\n             -Prunner=:runners:google-cloud-dataflow-java \\\n             -Prunner.version=V2 \\\n-            '-PloadTest.args=${{ env.beam_LoadTests_Java_GBK_Dataflow_V2_Streaming_test_arguments_7 }}'\n\\ No newline at end of file\n+            '-PloadTest.args=${{ env.beam_LoadTests_Java_GBK_Dataflow_V2_Streaming_test_arguments_7 }}'\n@@ -165,4 +165,4 @@ jobs:\n             -Prunner.version=V2 \\\n             -PtestJavaVersion=17 \\\n             -Pjava17Home=$JAVA_HOME_17_X64 \\\n-            '-PloadTest.args=${{ env.beam_LoadTests_Java_GBK_Dataflow_V2_Streaming_Java17_test_arguments_7 }}'\n\\ No newline at end of file\n+            '-PloadTest.args=${{ env.beam_LoadTests_Java_GBK_Dataflow_V2_Streaming_Java17_test_arguments_7 }}'\n@@ -87,15 +87,15 @@ jobs:\n         uses: ./.github/actions/gradle-command-self-hosted-action\n         with:\n           gradle-command: :sdks:java:testing:load-tests:run\n-          arguments: |            \n+          arguments: |\n             -PloadTest.mainClass=org.apache.beam.sdk.loadtests.GroupByKeyLoadTest \\\n             -Prunner=:runners:direct-java  \\\n             '-PloadTest.args=${{ env.beam_LoadTests_Java_GBK_Smoke_test_arguments_1 }}' \\\n       - name: run GroupByKey load test Dataflow\n         uses: ./.github/actions/gradle-command-self-hosted-action\n         with:\n           gradle-command: :sdks:java:testing:load-tests:run\n-          arguments: |            \n+          arguments: |\n             -PloadTest.mainClass=org.apache.beam.sdk.loadtests.GroupByKeyLoadTest \\\n             -Prunner=:runners:google-cloud-dataflow-java \\\n             '-PloadTest.args=${{ env.beam_LoadTests_Java_GBK_Smoke_test_arguments_2 }}' \\\n@@ -140,4 +140,4 @@ jobs:\n           arguments: |\n             -PloadTest.mainClass=org.apache.beam.sdk.loadtests.GroupByKeyLoadTest \\\n             -Prunner=:runners:spark:3 \\\n-            '-PloadTest.args=${{ env.beam_LoadTests_Java_GBK_SparkStructuredStreaming_Batch_test_arguments_7 }}'\n\\ No newline at end of file\n+            '-PloadTest.args=${{ env.beam_LoadTests_Java_GBK_SparkStructuredStreaming_Batch_test_arguments_7 }}'\n@@ -113,4 +113,4 @@ jobs:\n           arguments: |\n             -PloadTest.mainClass=org.apache.beam.sdk.loadtests.ParDoLoadTest \\\n             -Prunner=:runners:google-cloud-dataflow-java \\\n-            '-PloadTest.args=${{ env.beam_LoadTests_Java_ParDo_Dataflow_Batch_test_arguments_4 }}'\n\\ No newline at end of file\n+            '-PloadTest.args=${{ env.beam_LoadTests_Java_ParDo_Dataflow_Batch_test_arguments_4 }}'\n@@ -113,4 +113,4 @@ jobs:\n           arguments: |\n             -PloadTest.mainClass=org.apache.beam.sdk.loadtests.ParDoLoadTest \\\n             -Prunner=:runners:google-cloud-dataflow-java \\\n-            '-PloadTest.args=${{ env.beam_LoadTests_Java_ParDo_Dataflow_Streaming_test_arguments_4 }}'\n\\ No newline at end of file\n+            '-PloadTest.args=${{ env.beam_LoadTests_Java_ParDo_Dataflow_Streaming_test_arguments_4 }}'\n@@ -133,4 +133,4 @@ jobs:\n             -Prunner.version=V2 \\\n             -PtestJavaVersion=${{ matrix.java_version }} \\\n             -Pjava${{ matrix.java_version }}Home=$JAVA_HOME_${{ matrix.java_version }}_X64 \\\n-            '-PloadTest.args=${{ env.beam_LoadTests_Java_ParDo_Dataflow_V2_Batch_JavaVersions_test_arguments_4 }} --appName=load_tests_Java${{ matrix.java_version }}_Dataflow_V2_batch_ParDo_4'\n\\ No newline at end of file\n+            '-PloadTest.args=${{ env.beam_LoadTests_Java_ParDo_Dataflow_V2_Batch_JavaVersions_test_arguments_4 }} --appName=load_tests_Java${{ matrix.java_version }}_Dataflow_V2_batch_ParDo_4'\n@@ -133,4 +133,4 @@ jobs:\n             -Prunner.version=V2 \\\n             -PtestJavaVersion=${{ matrix.java_version }} \\\n             -Pjava${{ matrix.java_version }}Home=$JAVA_HOME_${{ matrix.java_version }}_X64 \\\n-            '-PloadTest.args=${{ env.beam_LoadTests_Java_ParDo_Dataflow_V2_Streaming_JavaVersions_test_arguments_4 }} --appName=load_tests_Java${{ matrix.java_version }}_Dataflow_V2_streaming_ParDo_4'\n\\ No newline at end of file\n+            '-PloadTest.args=${{ env.beam_LoadTests_Java_ParDo_Dataflow_V2_Streaming_JavaVersions_test_arguments_4 }} --appName=load_tests_Java${{ matrix.java_version }}_Dataflow_V2_streaming_ParDo_4'\n@@ -113,4 +113,4 @@ jobs:\n           arguments: |\n             -PloadTest.mainClass=org.apache.beam.sdk.loadtests.ParDoLoadTest \\\n             -Prunner=:runners:spark:3 \\\n-            '-PloadTest.args=${{ env.beam_LoadTests_Java_ParDo_SparkStructuredStreaming_Batch_test_arguments_4 }}'\n\\ No newline at end of file\n+            '-PloadTest.args=${{ env.beam_LoadTests_Java_ParDo_SparkStructuredStreaming_Batch_test_arguments_4 }}'\n@@ -74,4 +74,4 @@ jobs:\n       - name: run PubSub Performance test\n         uses: ./.github/actions/gradle-command-self-hosted-action\n         with:\n-          gradle-command: :it:google-cloud-platform:PubsubLoadTestLarge --info -DinfluxHost=\"http://10.128.0.96:8086\" -DinfluxDatabase=\"beam_test_metrics\" -DinfluxMeasurement=\"java_load_test_pubsub\"\n\\ No newline at end of file\n+          gradle-command: :it:google-cloud-platform:PubsubLoadTestLarge --info -DinfluxHost=\"http://10.128.0.96:8086\" -DinfluxDatabase=\"beam_test_metrics\" -DinfluxMeasurement=\"java_load_test_pubsub\"\n@@ -85,7 +85,7 @@ jobs:\n             ${{ github.workspace }}/.github/workflows/load-tests-pipeline-options/python_CoGBK_Dataflow_Batch_2MB.txt\n       - name: Set current datetime\n         id: datetime\n-        run: | \n+        run: |\n           echo \"datetime=$(date '+%m%d%H%M%S' --utc)\" >> $GITHUB_OUTPUT\n       # The env variables are created and populated in the test-arguments-action as \"<github.job>_test_arguments_<argument_file_paths_index>\"\n       - name: run CoGBK 2GB of 100B records with a single key\n@@ -124,4 +124,4 @@ jobs:\n             -PloadTest.mainClass=apache_beam.testing.load_tests.co_group_by_key_test \\\n             -Prunner=DataflowRunner \\\n             -PpythonVersion=3.9 \\\n-            '-PloadTest.args=${{ env.beam_LoadTests_Python_CoGBK_Dataflow_Batch_test_arguments_4 }} --job_name=load-tests-python-dataflow-batch-cogbk-4-${{ steps.datetime.outputs.datetime }}'\n\\ No newline at end of file\n+            '-PloadTest.args=${{ env.beam_LoadTests_Python_CoGBK_Dataflow_Batch_test_arguments_4 }} --job_name=load-tests-python-dataflow-batch-cogbk-4-${{ steps.datetime.outputs.datetime }}'\n@@ -123,4 +123,4 @@ jobs:\n             -PloadTest.mainClass=apache_beam.testing.load_tests.co_group_by_key_test \\\n             -Prunner=DataflowRunner \\\n             -PpythonVersion=3.9 \\\n-            '-PloadTest.args=${{ env.beam_LoadTests_Python_CoGBK_Dataflow_Streaming_test_arguments_4 }} --job_name=load-tests-python-dataflow-streaming-cogbk-4-${{ steps.datetime.outputs.datetime }}'\n\\ No newline at end of file\n+            '-PloadTest.args=${{ env.beam_LoadTests_Python_CoGBK_Dataflow_Streaming_test_arguments_4 }} --job_name=load-tests-python-dataflow-streaming-cogbk-4-${{ steps.datetime.outputs.datetime }}'\n@@ -132,4 +132,4 @@ jobs:\n       - name: Teardown Flink\n         if: always()\n         run: |\n-          ${{ github.workspace }}/.test-infra/dataproc/flink_cluster.sh delete\n\\ No newline at end of file\n+          ${{ github.workspace }}/.test-infra/dataproc/flink_cluster.sh delete\n@@ -111,4 +111,4 @@ jobs:\n             -PloadTest.mainClass=apache_beam.testing.load_tests.combine_test \\\n             -Prunner=DataflowRunner \\\n             -PpythonVersion=3.9 \\\n-            '-PloadTest.args=${{ env.beam_LoadTests_Python_Combine_Dataflow_Batch_test_arguments_3 }} --job_name=load-tests-python-dataflow-batch-combine-3-${{env.NOW_UTC}}'\n\\ No newline at end of file\n+            '-PloadTest.args=${{ env.beam_LoadTests_Python_Combine_Dataflow_Batch_test_arguments_3 }} --job_name=load-tests-python-dataflow-batch-combine-3-${{env.NOW_UTC}}'\n@@ -111,4 +111,4 @@ jobs:\n             -PloadTest.mainClass=apache_beam.testing.load_tests.combine_test \\\n             -Prunner=DataflowRunner \\\n             -PpythonVersion=3.9 \\\n-            '-PloadTest.args=${{ env.beam_LoadTests_Python_Combine_Dataflow_Streaming_test_arguments_3 }} --job_name=load-tests-python-dataflow-streaming-combine-5-${{env.NOW_UTC}}'\n\\ No newline at end of file\n+            '-PloadTest.args=${{ env.beam_LoadTests_Python_Combine_Dataflow_Streaming_test_arguments_3 }} --job_name=load-tests-python-dataflow-streaming-combine-5-${{env.NOW_UTC}}'\n@@ -99,7 +99,7 @@ jobs:\n           cd ${{ github.workspace }}/.test-infra/dataproc; ./flink_cluster.sh create\n       - name: get current time\n         run: echo \"NOW_UTC=$(date '+%m%d%H%M%S' --utc)\" >> $GITHUB_ENV\n-      # The env variables are created and populated in the test-arguments-action as \"<github.job>_test_arguments_<argument_file_paths_index>\"  \n+      # The env variables are created and populated in the test-arguments-action as \"<github.job>_test_arguments_<argument_file_paths_index>\"\n       - name: run Load test 2GB 10 byte records\n         env:\n           CLOUDSDK_CONFIG: ${{ env.KUBELET_GCLOUD_CONFIG_PATH}}\n@@ -137,4 +137,4 @@ jobs:\n       - name: Teardown Flink\n         if: always()\n         run: |\n-          ${{ github.workspace }}/.test-infra/dataproc/flink_cluster.sh delete\n\\ No newline at end of file\n+          ${{ github.workspace }}/.test-infra/dataproc/flink_cluster.sh delete\n@@ -88,4 +88,4 @@ jobs:\n             -PloadTest.mainClass=apache_beam.testing.load_tests.microbenchmarks_test \\\n             -Prunner=DirectRunner \\\n             -PpythonVersion=3.9 \\\n-            '-PloadTest.args=${{ env.beam_LoadTests_Python_FnApiRunner_Microbenchmark_test_arguments_1 }}'\n\\ No newline at end of file\n+            '-PloadTest.args=${{ env.beam_LoadTests_Python_FnApiRunner_Microbenchmark_test_arguments_1 }}'\n@@ -131,4 +131,4 @@ jobs:\n             -PloadTest.mainClass=apache_beam.testing.load_tests.group_by_key_test \\\n             -Prunner=DataflowRunner \\\n             -PpythonVersion=3.9 \\\n-            '-PloadTest.args=${{ env.beam_LoadTests_Python_GBK_Dataflow_Batch_test_arguments_5 }} --job_name=load-tests-python-dataflow-batch-gbk-5-${{env.NOW_UTC}}'\n\\ No newline at end of file\n+            '-PloadTest.args=${{ env.beam_LoadTests_Python_GBK_Dataflow_Batch_test_arguments_5 }} --job_name=load-tests-python-dataflow-batch-gbk-5-${{env.NOW_UTC}}'\n@@ -92,9 +92,9 @@ jobs:\n             -Prunner=DataflowRunner \\\n             -PpythonVersion=3.9 \\\n             '-PloadTest.args=${{ env.beam_LoadTests_Python_GBK_Dataflow_Streaming_test_arguments_1 }} --job_name=load-tests-python-dataflow-streaming-gbk-3-${{env.NOW_UTC}}' \\\n-            \n+\n           # // TODO(https://github.com/apache/beam/issues/20403). Skipping some cases because they are too slow:\n           # load-tests-python-dataflow-streaming-gbk-1\n           # load-tests-python-dataflow-streaming-gbk-2\n           # load-tests-python-dataflow-streaming-gbk-4\n-          # load-tests-python-dataflow-streaming-gbk-5\n\\ No newline at end of file\n+          # load-tests-python-dataflow-streaming-gbk-5\n@@ -151,5 +151,5 @@ jobs:\n         if: always()\n         run: |\n           ${{ github.workspace }}/.test-infra/dataproc/flink_cluster.sh delete\n-        \n-        # TODO(https://github.com/apache/beam/issues/20146) Re-enable auto builds after these tests pass.\n\\ No newline at end of file\n+\n+        # TODO(https://github.com/apache/beam/issues/20146) Re-enable auto builds after these tests pass.\n@@ -101,4 +101,4 @@ jobs:\n             -PloadTest.mainClass=apache_beam.testing.load_tests.group_by_key_test \\\n             -Prunner=DataflowRunner \\\n             -PpythonVersion=3.9 \\\n-            '-PloadTest.args=${{ env.beam_LoadTests_Python_GBK_reiterate_Dataflow_Batch_test_arguments_2 }} --job_name=load-tests-python-dataflow-batch-gbk-7-${{env.NOW_UTC}}'\n\\ No newline at end of file\n+            '-PloadTest.args=${{ env.beam_LoadTests_Python_GBK_reiterate_Dataflow_Batch_test_arguments_2 }} --job_name=load-tests-python-dataflow-batch-gbk-7-${{env.NOW_UTC}}'\n@@ -123,4 +123,4 @@ jobs:\n             -PloadTest.mainClass=apache_beam.testing.load_tests.pardo_test \\\n             -Prunner=DataflowRunner \\\n             -PpythonVersion=3.9 \\\n-            '-PloadTest.args=${{ env.beam_LoadTests_Python_ParDo_Dataflow_Batch_test_arguments_4 }} --job_name=load-tests-python-dataflow-batch-pardo-4-${{ steps.datetime.outputs.datetime }}'\n\\ No newline at end of file\n+            '-PloadTest.args=${{ env.beam_LoadTests_Python_ParDo_Dataflow_Batch_test_arguments_4 }} --job_name=load-tests-python-dataflow-batch-pardo-4-${{ steps.datetime.outputs.datetime }}'\n@@ -123,4 +123,4 @@ jobs:\n             -PloadTest.mainClass=apache_beam.testing.load_tests.pardo_test \\\n             -Prunner=DataflowRunner \\\n             -PpythonVersion=3.9 \\\n-            '-PloadTest.args=${{ env.beam_LoadTests_Python_ParDo_Dataflow_Streaming_test_arguments_4 }} --job_name=load-tests-python-dataflow-streaming-pardo-4-${{ steps.datetime.outputs.datetime }}'\n\\ No newline at end of file\n+            '-PloadTest.args=${{ env.beam_LoadTests_Python_ParDo_Dataflow_Streaming_test_arguments_4 }} --job_name=load-tests-python-dataflow-streaming-pardo-4-${{ steps.datetime.outputs.datetime }}'\n@@ -128,4 +128,4 @@ jobs:\n             -PloadTest.mainClass=apache_beam.testing.load_tests.pardo_test \\\n             -Prunner=PortableRunner \\\n             -PpythonVersion=3.9 \\\n-            '-PloadTest.args=${{ env.beam_LoadTests_Python_ParDo_Flink_Batch_test_arguments_3 }} --job_name=load-tests-python-flink-batch-pardo-4-${{ steps.datetime.outputs.datetime }}'\n\\ No newline at end of file\n+            '-PloadTest.args=${{ env.beam_LoadTests_Python_ParDo_Flink_Batch_test_arguments_3 }} --job_name=load-tests-python-flink-batch-pardo-4-${{ steps.datetime.outputs.datetime }}'\n@@ -152,4 +152,4 @@ jobs:\n       - name: Teardown Flink\n         if: always()\n         run: |\n-          ${{ github.workspace }}/.test-infra/dataproc/flink_cluster.sh delete\n\\ No newline at end of file\n+          ${{ github.workspace }}/.test-infra/dataproc/flink_cluster.sh delete\n@@ -183,4 +183,4 @@ jobs:\n             -PloadTest.mainClass=apache_beam.testing.load_tests.sideinput_test \\\n             -Prunner=DataflowRunner \\\n             -PpythonVersion=3.9 \\\n-            '-PloadTest.args=${{ env.beam_LoadTests_Python_SideInput_Dataflow_Batch_test_arguments_10 }} --job_name=load-tests-python-dataflow-batch-sideinput-10-${{ steps.datetime.outputs.datetime }}'\n\\ No newline at end of file\n+            '-PloadTest.args=${{ env.beam_LoadTests_Python_SideInput_Dataflow_Batch_test_arguments_10 }} --job_name=load-tests-python-dataflow-batch-sideinput-10-${{ steps.datetime.outputs.datetime }}'\n@@ -100,4 +100,4 @@ jobs:\n             -PloadTest.mainClass=apache_beam.testing.load_tests.group_by_key_test \\\n             -Prunner=DataflowRunner \\\n             -PpythonVersion=3.9 \\\n-            '-PloadTest.args=${{ env.beam_LoadTests_Python_Smoke_test_arguments_2 }} --job_name=load-tests-python-dataflow-batch-gbk-smoke-${{ steps.datetime.outputs.datetime }}'\n\\ No newline at end of file\n+            '-PloadTest.args=${{ env.beam_LoadTests_Python_Smoke_test_arguments_2 }} --job_name=load-tests-python-dataflow-batch-gbk-smoke-${{ steps.datetime.outputs.datetime }}'\n@@ -58,7 +58,7 @@ jobs:\n         (github.event_name == 'schedule' && github.repository == 'apache/beam')\n         || github.event_name == 'workflow_dispatch'\n       )\n-     \n+\n     steps:\n       - uses: actions/checkout@v4\n       - name: Setup environment\n@@ -103,4 +103,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -103,4 +103,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -103,4 +103,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -91,4 +91,4 @@ jobs:\n             -PloadTest.mainClass=apache_beam.io.gcp.bigquery_read_perf_test \\\n             -PpythonVersion=3.9 \\\n             -Prunner=DataflowRunner \\\n-            '-PloadTest.args=${{env.beam_PerformanceTests_BiqQueryIO_Read_Python_test_arguments_1}}'\n\\ No newline at end of file\n+            '-PloadTest.args=${{env.beam_PerformanceTests_BiqQueryIO_Read_Python_test_arguments_1}}'\n@@ -91,4 +91,4 @@ jobs:\n             -PloadTest.mainClass=apache_beam.io.gcp.bigquery_write_perf_test \\\n             -PpythonVersion=3.9 \\\n             -Prunner=DataflowRunner \\\n-            '-PloadTest.args=${{env.beam_PerformanceTests_BiqQueryIO_Write_Python_Batch_test_arguments_1}}'\n\\ No newline at end of file\n+            '-PloadTest.args=${{env.beam_PerformanceTests_BiqQueryIO_Write_Python_Batch_test_arguments_1}}'\n@@ -90,4 +90,4 @@ jobs:\n             --info \\\n             -Dfilesystem=gcs \\\n             -DintegrationTestRunner=dataflow \\\n-            -DintegrationTestPipelineOptions='[${{ env.beam_PerformanceTests_Compressed_TextIOIT_test_arguments_1 }}]'\n\\ No newline at end of file\n+            -DintegrationTestPipelineOptions='[${{ env.beam_PerformanceTests_Compressed_TextIOIT_test_arguments_1 }}]'\n@@ -102,4 +102,4 @@ jobs:\n             --info \\\n             -Dfilesystem=hdfs \\\n             -DintegrationTestRunner=dataflow \\\n-            -DintegrationTestPipelineOptions='[${{ env.beam_PerformanceTests_Compressed_TextIOIT_HDFS_test_arguments_1 }}]'\n\\ No newline at end of file\n+            -DintegrationTestPipelineOptions='[${{ env.beam_PerformanceTests_Compressed_TextIOIT_HDFS_test_arguments_1 }}]'\n@@ -102,4 +102,4 @@ jobs:\n             --info \\\n             -Dfilesystem=hdfs \\\n             -DintegrationTestRunner=dataflow \\\n-            -DintegrationTestPipelineOptions='[${{env.beam_PerformanceTests_JDBC_test_arguments_1}}]'\n\\ No newline at end of file\n+            -DintegrationTestPipelineOptions='[${{env.beam_PerformanceTests_JDBC_test_arguments_1}}]'\n@@ -120,4 +120,4 @@ jobs:\n             --tests org.apache.beam.sdk.io.kafka.KafkaIOIT.testKafkaIOReadsAndWritesCorrectlyInBatch \\\n             --info \\\n             -DintegrationTestRunner=dataflow \\\n-            -DintegrationTestPipelineOptions='[${{env.beam_PerformanceTests_Kafka_IO_test_arguments_2}}]'\n\\ No newline at end of file\n+            -DintegrationTestPipelineOptions='[${{env.beam_PerformanceTests_Kafka_IO_test_arguments_2}}]'\n@@ -90,4 +90,4 @@ jobs:\n             --info \\\n             -Dfilesystem=gcs \\\n             -DintegrationTestRunner=dataflow \\\n-            -DintegrationTestPipelineOptions='[${{ env.beam_PerformanceTests_ManyFiles_TextIOIT_test_arguments_1 }}]'\n\\ No newline at end of file\n+            -DintegrationTestPipelineOptions='[${{ env.beam_PerformanceTests_ManyFiles_TextIOIT_test_arguments_1 }}]'\n@@ -102,4 +102,4 @@ jobs:\n             --info \\\n             -Dfilesystem=hdfs \\\n             -DintegrationTestRunner=dataflow \\\n-            -DintegrationTestPipelineOptions='[${{ env.beam_PerformanceTests_ManyFiles_TextIOIT_HDFS_test_arguments_1 }}]'\n\\ No newline at end of file\n+            -DintegrationTestPipelineOptions='[${{ env.beam_PerformanceTests_ManyFiles_TextIOIT_HDFS_test_arguments_1 }}]'\n@@ -90,4 +90,4 @@ jobs:\n             --info \\\n             -Dfilesystem=gcs \\\n             -DintegrationTestRunner=dataflow \\\n-            -DintegrationTestPipelineOptions='[${{ env.beam_PerformanceTests_ParquetIOIT_test_arguments_1 }}]'\n\\ No newline at end of file\n+            -DintegrationTestPipelineOptions='[${{ env.beam_PerformanceTests_ParquetIOIT_test_arguments_1 }}]'\n@@ -102,4 +102,4 @@ jobs:\n             --info \\\n             -Dfilesystem=hdfs \\\n             -DintegrationTestRunner=dataflow \\\n-            -DintegrationTestPipelineOptions='[${{ env.beam_PerformanceTests_ParquetIOIT_HDFS_test_arguments_1 }}]'\n\\ No newline at end of file\n+            -DintegrationTestPipelineOptions='[${{ env.beam_PerformanceTests_ParquetIOIT_HDFS_test_arguments_1 }}]'\n@@ -91,4 +91,4 @@ jobs:\n             -PloadTest.mainClass=apache_beam.io.gcp.pubsub_io_perf_test \\\n             -Prunner=TestDataflowRunner \\\n             -PpythonVersion=3.9 \\\n-            '-PloadTest.args=${{ env.beam_PerformanceTests_PubsubIOIT_Python_Streaming_test_arguments_1 }}'\n\\ No newline at end of file\n+            '-PloadTest.args=${{ env.beam_PerformanceTests_PubsubIOIT_Python_Streaming_test_arguments_1 }}'\n@@ -102,4 +102,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -52,11 +52,11 @@ env:\n \n jobs:\n   beam_PerformanceTests_SingleStoreIO:\n-    name: ${{matrix.job_name}} (${{matrix.job_phrase}}) \n+    name: ${{matrix.job_name}} (${{matrix.job_phrase}})\n     runs-on: [self-hosted, ubuntu-20.04, main]\n     timeout-minutes: 100\n     strategy:\n-      matrix: \n+      matrix:\n         job_name: [beam_PerformanceTests_SingleStoreIO]\n         job_phrase: [Run Java SingleStoreIO Performance Test]\n     if: |\n@@ -79,7 +79,7 @@ jobs:\n           k8s_namespace: ${{ matrix.job_name }}-${{ github.run_id }}\n           remove_finalizer:  memsqlclusters.memsql.com/sdb-cluster\n       - name: Install Singlestore operator\n-        run: | \n+        run: |\n           kubectl apply -f ${{github.workspace}}/.test-infra/kubernetes/singlestore/sdb-rbac.yaml\n           kubectl apply -f ${{github.workspace}}/.test-infra/kubernetes/singlestore/sdb-cluster-crd.yaml\n           kubectl apply -f ${{github.workspace}}/.test-infra/kubernetes/singlestore/sdb-operator.yaml\n@@ -90,7 +90,7 @@ jobs:\n           kubectl apply -f ${{github.workspace}}/.test-infra/kubernetes/singlestore/sdb-cluster.yaml\n           kubectl wait --for=jsonpath='{.status.phase}'=Running memsqlclusters.memsql.com --all --timeout=300s\n           kubectl wait svc/svc-sdb-cluster-ddl --for=jsonpath='{.status.loadBalancer.ingress[0].ip}' --timeout=300s\n-          loadbalancer_IP=$(kubectl get svc svc-sdb-cluster-ddl -o jsonpath='{.status.loadBalancer.ingress[0].ip}') \n+          loadbalancer_IP=$(kubectl get svc svc-sdb-cluster-ddl -o jsonpath='{.status.loadBalancer.ingress[0].ip}')\n           echo lb_ip=$loadbalancer_IP >> $GITHUB_OUTPUT\n       - name: Prepare test arguments\n         uses: ./.github/actions/test-arguments-action\n@@ -106,9 +106,9 @@ jobs:\n         id: run_java_singlestore_io_performance_test\n         uses: ./.github/actions/gradle-command-self-hosted-action\n         with:\n-          gradle-command: :sdks:java:io:singlestore:integrationTest \n+          gradle-command: :sdks:java:io:singlestore:integrationTest\n           arguments: |\n             --tests org.apache.beam.sdk.io.singlestore.SingleStoreIOPerformanceIT \\\n             --info \\\n             -DintegrationTestRunner=dataflow \\\n-            -DintegrationTestPipelineOptions='[${{ env.beam_PerformanceTests_SingleStoreIO_test_arguments_1 }}]'\n\\ No newline at end of file\n+            -DintegrationTestPipelineOptions='[${{ env.beam_PerformanceTests_SingleStoreIO_test_arguments_1 }}]'\n@@ -91,4 +91,4 @@ jobs:\n             -PloadTest.mainClass=apache_beam.io.gcp.experimental.spannerio_read_perf_test \\\n             -Prunner=DataflowRunner \\\n             -PpythonVersion=3.9 \\\n-            -PloadTest.args='${{env.beam_PerformanceTests_SpannerIO_Read_2GB_Python_test_arguments_1}}'\n\\ No newline at end of file\n+            -PloadTest.args='${{env.beam_PerformanceTests_SpannerIO_Read_2GB_Python_test_arguments_1}}'\n@@ -91,4 +91,4 @@ jobs:\n             -PloadTest.mainClass=apache_beam.io.gcp.experimental.spannerio_write_perf_test \\\n             -Prunner=DataflowRunner \\\n             -PpythonVersion=3.9 \\\n-            -PloadTest.args='${{env.beam_PerformanceTests_SpannerIO_Write_2GB_Python_Batch_test_arguments_1}}'\n\\ No newline at end of file\n+            -PloadTest.args='${{env.beam_PerformanceTests_SpannerIO_Write_2GB_Python_Batch_test_arguments_1}}'\n@@ -90,4 +90,4 @@ jobs:\n             --info \\\n             -Dfilesystem=gcs \\\n             -DintegrationTestRunner=dataflow \\\n-            -DintegrationTestPipelineOptions='[${{ env.beam_PerformanceTests_TFRecordIOIT_test_arguments_1 }}]'\n\\ No newline at end of file\n+            -DintegrationTestPipelineOptions='[${{ env.beam_PerformanceTests_TFRecordIOIT_test_arguments_1 }}]'\n@@ -105,4 +105,4 @@ jobs:\n             --tests org.apache.beam.sdk.io.tfrecord.TFRecordIOIT \\\n             -Dfilesystem=hdfs \\\n             -DintegrationTestRunner=dataflow \\\n-            -DintegrationTestPipelineOptions='[${{ env.beam_PerformanceTests_TFRecordIOIT_HDFS_test_arguments_1 }}]' \\\n\\ No newline at end of file\n+            -DintegrationTestPipelineOptions='[${{ env.beam_PerformanceTests_TFRecordIOIT_HDFS_test_arguments_1 }}]' \\\n@@ -90,4 +90,4 @@ jobs:\n             --info \\\n             -Dfilesystem=gcs \\\n             -DintegrationTestRunner=dataflow \\\n-            '-DintegrationTestPipelineOptions=[${{env.beam_PerformanceTests_TextIOIT_test_arguments_1}}]'\n\\ No newline at end of file\n+            '-DintegrationTestPipelineOptions=[${{env.beam_PerformanceTests_TextIOIT_test_arguments_1}}]'\n@@ -103,4 +103,4 @@ jobs:\n             --info \\\n             -Dfilesystem=hdfs \\\n             -DintegrationTestRunner=dataflow \\\n-            -DintegrationTestPipelineOptions='[${{env.beam_PerformanceTests_TextIOIT_HDFS_test_arguments_1}}]'\n\\ No newline at end of file\n+            -DintegrationTestPipelineOptions='[${{env.beam_PerformanceTests_TextIOIT_HDFS_test_arguments_1}}]'\n@@ -91,4 +91,4 @@ jobs:\n             -PpythonVersion=3.9 \\\n             -PloadTest.mainClass=apache_beam.io.filebasedio_perf_test \\\n             -Prunner=DataflowRunner \\\n-            '-PloadTest.args=${{env.beam_PerformanceTests_TextIOIT_Python_test_arguments_1}}'\n\\ No newline at end of file\n+            '-PloadTest.args=${{env.beam_PerformanceTests_TextIOIT_Python_test_arguments_1}}'\n@@ -116,4 +116,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/pytest*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -90,4 +90,4 @@ jobs:\n             --info \\\n             -Dfilesystem=gcs \\\n             -DintegrationTestRunner=dataflow \\\n-            -DintegrationTestPipelineOptions='[${{ env.beam_PerformanceTests_XmlIOIT_test_arguments_1 }}]'\n\\ No newline at end of file\n+            -DintegrationTestPipelineOptions='[${{ env.beam_PerformanceTests_XmlIOIT_test_arguments_1 }}]'\n@@ -102,4 +102,4 @@ jobs:\n             --info \\\n             -Dfilesystem=hdfs \\\n             -DintegrationTestRunner=dataflow \\\n-            -DintegrationTestPipelineOptions='[${{ env.beam_PerformanceTests_XmlIOIT_HDFS_test_arguments_1 }}]'\n\\ No newline at end of file\n+            -DintegrationTestPipelineOptions='[${{ env.beam_PerformanceTests_XmlIOIT_HDFS_test_arguments_1 }}]'\n@@ -120,4 +120,4 @@ jobs:\n             -Prunner=DataflowRunner \\\n             -PloadTest.mainClass=apache_beam.io.external.xlang_kafkaio_perf_test \\\n             -PpythonVersion=3.9 \\\n-            '-PloadTest.args=${{ env.beam_PerfTests_xlang_KafkaIO_Python_test_arguments_1 }}'\n\\ No newline at end of file\n+            '-PloadTest.args=${{ env.beam_PerfTests_xlang_KafkaIO_Python_test_arguments_1 }}'\n@@ -57,7 +57,7 @@ jobs:\n     runs-on: [self-hosted, ubuntu-20.04, highmem]\n     name: \"beam_Playground_CI_Nightly\"\n     strategy:\n-      matrix: \n+      matrix:\n         sdk: [\"python\", \"java\", \"go\"]\n       fail-fast: false\n     steps:\n@@ -88,11 +88,11 @@ jobs:\n           CONTAINER_ID=$(docker run -d -e PROTOCOL_TYPE=TCP apache/beam_playground-backend-${{ matrix.sdk }}:nightly)\n           echo \"container_id=$CONTAINER_ID\" >> $GITHUB_ENV\n       - name: Get Container IP\n-        run: | \n+        run: |\n           CONTAINER_IP=$(docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' ${{ env.container_id }})\n           echo \"container_ip=$CONTAINER_IP\" >> $GITHUB_ENV\n       - name: Run CI\n-        env: \n+        env:\n           SERVER_ADDRESS: ${{ env.container_ip }}:8080\n           BEAM_EXAMPLE_CATEGORIES: ${{ env.BEAM_ROOT_DIR }}/playground/categories.yaml\n           SDK: ${{ matrix.sdk }}\n@@ -85,4 +85,4 @@ jobs:\n           gradle-command: :goPostCommit\n           arguments: |\n             --no-parallel \\\n-            -Pdocker-repository-root=us.gcr.io/apache-beam-testing/github-actions\n\\ No newline at end of file\n+            -Pdocker-repository-root=us.gcr.io/apache-beam-testing/github-actions\n@@ -77,4 +77,4 @@ jobs:\n           CLOUDSDK_CONFIG: ${{ env.KUBELET_GCLOUD_CONFIG_PATH}}\n         uses: ./.github/actions/gradle-command-self-hosted-action\n         with:\n-          gradle-command: :sdks:go:test:flinkValidatesRunner\n\\ No newline at end of file\n+          gradle-command: :sdks:go:test:flinkValidatesRunner\n@@ -78,4 +78,3 @@ jobs:\n         uses: ./.github/actions/gradle-command-self-hosted-action\n         with:\n           gradle-command: :sdks:go:test:sparkValidatesRunner\n-          \n\\ No newline at end of file\n@@ -91,4 +91,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -56,7 +56,7 @@ jobs:\n     runs-on: [self-hosted, ubuntu-20.04, main]\n     timeout-minutes: 240\n     strategy:\n-      matrix: \n+      matrix:\n         job_name: [beam_PostCommit_Java_Avro_Versions]\n         job_phrase: [Run Java Avro Versions PostCommit]\n     if: |\n@@ -91,4 +91,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -93,4 +93,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -91,4 +91,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -90,4 +90,4 @@ jobs:\n       if: always()\n       with:\n         files: '**/build/test-results/**/*.xml'\n-        large_files: true\n\\ No newline at end of file\n+        large_files: true\n@@ -59,7 +59,7 @@ jobs:\n     timeout-minutes: 120\n     strategy:\n       fail-fast: false\n-      matrix: \n+      matrix:\n         job_name: [beam_PostCommit_Java_Examples_Dataflow_ARM]\n         job_phrase: [Run Java_Examples_Dataflow_ARM PostCommit]\n         java_version: ['8','11','17','21']\n@@ -98,4 +98,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -56,7 +56,7 @@ jobs:\n     runs-on: [self-hosted, ubuntu-20.04, main]\n     timeout-minutes: 180\n     strategy:\n-      matrix: \n+      matrix:\n         job_name: [beam_PostCommit_Java_Examples_Dataflow_V2]\n         job_phrase: [Run Java Examples on Dataflow Runner V2]\n     if: |\n@@ -105,4 +105,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -93,4 +93,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -93,4 +93,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -49,7 +49,7 @@ env:\n   GRADLE_ENTERPRISE_CACHE_PASSWORD: ${{ secrets.GE_CACHE_PASSWORD }}\n \n jobs:\n-  beam_PostCommit_Java_Hadoop_Versions:    \n+  beam_PostCommit_Java_Hadoop_Versions:\n     name: ${{ matrix.job_name }} (${{ matrix.job_phrase }})\n     runs-on: [self-hosted, ubuntu-20.04, main]\n     timeout-minutes: 240\n@@ -101,4 +101,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -56,7 +56,7 @@ jobs:\n     runs-on: [self-hosted, ubuntu-20.04, main]\n     timeout-minutes: 100\n     strategy:\n-      matrix: \n+      matrix:\n         job_name: [beam_PostCommit_Java_InfluxDbIO_IT]\n         job_phrase: [Run Java InfluxDbIO_IT]\n     if: |\n@@ -81,10 +81,10 @@ jobs:\n           k8s_namespace: ${{ matrix.job_name }}-${{ github.run_id }}\n       - name: Install InfluxDB\n         id: install_influxdb\n-        run: | \n+        run: |\n           kubectl apply -f ${{ github.workspace }}/.test-infra/kubernetes/influxdb/influxdb.yml\n           kubectl wait --timeout 2m svc/influxdb-load-balancer-service --for=jsonpath='{.status.loadBalancer.ingress[0].ip}'\n-          loadbalancer_IP=$(kubectl get svc influxdb-load-balancer-service -o jsonpath='{.status.loadBalancer.ingress[0].ip}') \n+          loadbalancer_IP=$(kubectl get svc influxdb-load-balancer-service -o jsonpath='{.status.loadBalancer.ingress[0].ip}')\n           echo influxdb_IP=$loadbalancer_IP >> $GITHUB_OUTPUT\n       - name: Run Java InfluxDbIO_IT\n         uses: ./.github/actions/gradle-command-self-hosted-action\n@@ -92,4 +92,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -97,4 +97,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -92,4 +92,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -97,4 +97,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -98,4 +98,4 @@ jobs:\n         commit: '${{ env.prsha || env.GITHUB_SHA }}'\n         comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n         files: '**/build/test-results/**/*.xml'\n-        large_files: true\n\\ No newline at end of file\n+        large_files: true\n@@ -92,4 +92,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -92,4 +92,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -50,27 +50,27 @@ env:\n   GRADLE_ENTERPRISE_CACHE_USERNAME: ${{ secrets.GE_CACHE_USERNAME }}\n   GRADLE_ENTERPRISE_CACHE_PASSWORD: ${{ secrets.GE_CACHE_PASSWORD }}\n   GRADLE_COMMAND_ARGUMENTS: |\n-    -Pnexmark.args=--manageResources=false \n-    --monitorJobs=true \n-    --bigQueryTable=nexmark \n-    --bigQueryDataset=nexmark \n-    --project=apache-beam-testing \n-    --resourceNameMode=QUERY_RUNNER_AND_MODE \n-    --exportSummaryToBigQuery=true \n-    --tempLocation=gs://temp-storage-for-perf-tests/nexmark \n-    --influxDatabase=beam_test_metrics \n-    --influxHost=http://10.128.0.96:8086 \n-    --baseInfluxMeasurement=nexmark \n-    --exportSummaryToInfluxDB=true \n-    --influxRetentionPolicy=forever \n-    --region=us-central1 \n-    --suite=STRESS \n-    --numWorkers=4 \n-    --maxNumWorkers=4 \n-    --autoscalingAlgorithm=NONE \n-    --nexmarkParallel=16 \n-    --enforceEncodability=true \n-    --enforceImmutability=true \n+    -Pnexmark.args=--manageResources=false\n+    --monitorJobs=true\n+    --bigQueryTable=nexmark\n+    --bigQueryDataset=nexmark\n+    --project=apache-beam-testing\n+    --resourceNameMode=QUERY_RUNNER_AND_MODE\n+    --exportSummaryToBigQuery=true\n+    --tempLocation=gs://temp-storage-for-perf-tests/nexmark\n+    --influxDatabase=beam_test_metrics\n+    --influxHost=http://10.128.0.96:8086\n+    --baseInfluxMeasurement=nexmark\n+    --exportSummaryToInfluxDB=true\n+    --influxRetentionPolicy=forever\n+    --region=us-central1\n+    --suite=STRESS\n+    --numWorkers=4\n+    --maxNumWorkers=4\n+    --autoscalingAlgorithm=NONE\n+    --nexmarkParallel=16\n+    --enforceEncodability=true\n+    --enforceImmutability=true\n     --runner=DataflowRunner\n   INFLUXDB_USER: ${{ secrets.INFLUXDB_USER }}\n   INFLUXDB_USER_PASSWORD: ${{ secrets.INFLUXDB_USER_PASSWORD }}\n@@ -117,4 +117,4 @@ jobs:\n           gradle-command: :sdks:java:testing:nexmark:run\n           arguments: |\n             -Pnexmark.runner=:runners:google-cloud-dataflow-java \\\n-            \"${{ env.GRADLE_COMMAND_ARGUMENTS }}--streaming=${{ matrix.streaming }}\"\n\\ No newline at end of file\n+            \"${{ env.GRADLE_COMMAND_ARGUMENTS }}--streaming=${{ matrix.streaming }}\"\n@@ -50,28 +50,28 @@ env:\n   GRADLE_ENTERPRISE_CACHE_USERNAME: ${{ secrets.GE_CACHE_USERNAME }}\n   GRADLE_ENTERPRISE_CACHE_PASSWORD: ${{ secrets.GE_CACHE_PASSWORD }}\n   GRADLE_COMMAND_ARGUMENTS: |\n-    -Pnexmark.args=--manageResources=false \n-    --monitorJobs=true \n-    --bigQueryTable=nexmark \n-    --bigQueryDataset=nexmark \n-    --project=apache-beam-testing \n-    --resourceNameMode=QUERY_RUNNER_AND_MODE \n-    --exportSummaryToBigQuery=false \n-    --tempLocation=gs://temp-storage-for-perf-tests/nexmark \n-    --influxDatabase=beam_test_metrics \n-    --influxHost=http://10.128.0.96:8086 \n-    --baseInfluxMeasurement=nexmark \n-    --exportSummaryToInfluxDB=true \n-    --influxRetentionPolicy=forever \n-    --influxTags={\"runnerVersion\":\"V2\",\"javaVersion\":\"8\"} \n-    --region=us-central1 \n-    --suite=STRESS \n-    --numWorkers=4 \n-    --maxNumWorkers=4 \n+    -Pnexmark.args=--manageResources=false\n+    --monitorJobs=true\n+    --bigQueryTable=nexmark\n+    --bigQueryDataset=nexmark\n+    --project=apache-beam-testing\n+    --resourceNameMode=QUERY_RUNNER_AND_MODE\n+    --exportSummaryToBigQuery=false\n+    --tempLocation=gs://temp-storage-for-perf-tests/nexmark\n+    --influxDatabase=beam_test_metrics\n+    --influxHost=http://10.128.0.96:8086\n+    --baseInfluxMeasurement=nexmark\n+    --exportSummaryToInfluxDB=true\n+    --influxRetentionPolicy=forever\n+    --influxTags={\"runnerVersion\":\"V2\",\"javaVersion\":\"8\"}\n+    --region=us-central1\n+    --suite=STRESS\n+    --numWorkers=4\n+    --maxNumWorkers=4\n     --autoscalingAlgorithm=NONE\n     --nexmarkParallel=16\n-    --enforceEncodability=true \n-    --enforceImmutability=true \n+    --enforceEncodability=true\n+    --enforceImmutability=true\n     --runner=DataflowRunner\n   INFLUXDB_USER: ${{ secrets.INFLUXDB_USER }}\n   INFLUXDB_USER_PASSWORD: ${{ secrets.INFLUXDB_USER_PASSWORD }}\n@@ -115,4 +115,4 @@ jobs:\n             -Pjava8Home=$JAVA_HOME_8_X64 \\\n             -Pnexmark.runner.version=V2 \\\n             -Pnexmark.runner=:runners:google-cloud-dataflow-java \\\n-            '${{ env.GRADLE_COMMAND_ARGUMENTS }}--streaming=${{ matrix.streaming }}'\n\\ No newline at end of file\n+            '${{ env.GRADLE_COMMAND_ARGUMENTS }}--streaming=${{ matrix.streaming }}'\n@@ -50,27 +50,27 @@ env:\n   GRADLE_ENTERPRISE_CACHE_USERNAME: ${{ secrets.GE_CACHE_USERNAME }}\n   GRADLE_ENTERPRISE_CACHE_PASSWORD: ${{ secrets.GE_CACHE_PASSWORD }}\n   GRADLE_COMMAND_ARGUMENTS: |\n-    -Pnexmark.args=--manageResources=false \n-    --monitorJobs=true \n+    -Pnexmark.args=--manageResources=false\n+    --monitorJobs=true\n     --bigQueryTable=nexmark\n     --bigQueryDataset=nexmark\n     --project=apache-beam-testing\n     --resourceNameMode=QUERY_RUNNER_AND_MODE\n-    --exportSummaryToBigQuery=false \n-    --tempLocation=gs://temp-storage-for-perf-tests/nexmark \n-    --influxDatabase=beam_test_metrics \n-    --influxHost=http://10.128.0.96:8086 \n-    --baseInfluxMeasurement=nexmark \n-    --exportSummaryToInfluxDB=true \n-    --influxRetentionPolicy=forever \n-    --region=us-central1 \n-    --suite=STRESS \n-    --numWorkers=4 \n-    --maxNumWorkers=4 \n-    --autoscalingAlgorithm=NONE \n-    --nexmarkParallel=16 \n-    --enforceEncodability=true \n-    --enforceImmutability=true \n+    --exportSummaryToBigQuery=false\n+    --tempLocation=gs://temp-storage-for-perf-tests/nexmark\n+    --influxDatabase=beam_test_metrics\n+    --influxHost=http://10.128.0.96:8086\n+    --baseInfluxMeasurement=nexmark\n+    --exportSummaryToInfluxDB=true\n+    --influxRetentionPolicy=forever\n+    --region=us-central1\n+    --suite=STRESS\n+    --numWorkers=4\n+    --maxNumWorkers=4\n+    --autoscalingAlgorithm=NONE\n+    --nexmarkParallel=16\n+    --enforceEncodability=true\n+    --enforceImmutability=true\n     --runner=DataflowRunner\n   INFLUXDB_USER: ${{ secrets.INFLUXDB_USER }}\n   INFLUXDB_USER_PASSWORD: ${{ secrets.INFLUXDB_USER_PASSWORD }}\n@@ -115,4 +115,4 @@ jobs:\n             -Pjava${{ matrix.java_version }}Home=$JAVA_HOME_${{ matrix.java_version }}_X64 \\\n             -Pnexmark.runner.version=V2 \\\n             -Pnexmark.runner=:runners:google-cloud-dataflow-java \\\n-            '${{ env.GRADLE_COMMAND_ARGUMENTS }}--influxTags={\"runnerVersion\":\"V2\",\"javaVersion\":\"${{ matrix.java_version }}\"}--streaming=${{ matrix.streaming }}'\n\\ No newline at end of file\n+            '${{ env.GRADLE_COMMAND_ARGUMENTS }}--influxTags={\"runnerVersion\":\"V2\",\"javaVersion\":\"${{ matrix.java_version }}\"}--streaming=${{ matrix.streaming }}'\n@@ -50,22 +50,22 @@ env:\n   GRADLE_ENTERPRISE_CACHE_USERNAME: ${{ secrets.GE_CACHE_USERNAME }}\n   GRADLE_ENTERPRISE_CACHE_PASSWORD: ${{ secrets.GE_CACHE_PASSWORD }}\n   GRADLE_COMMAND_ARGUMENTS: |\n-    -Pnexmark.args=--manageResources=false \n-    --monitorJobs=true \n-    --bigQueryTable=nexmark \n-    --bigQueryDataset=nexmark \n-    --project=apache-beam-testing \n-    --resourceNameMode=QUERY_RUNNER_AND_MODE \n-    --exportSummaryToBigQuery=true \n-    --tempLocation=gs://temp-storage-for-perf-tests/nexmark \n-    --influxDatabase=beam_test_metrics \n-    --influxHost=http://10.128.0.96:8086 \n-    --baseInfluxMeasurement=nexmark \n-    --exportSummaryToInfluxDB=true \n-    --influxRetentionPolicy=forever \n-    --suite=SMOKE \n-    --enforceEncodability=true \n-    --enforceImmutability=true \n+    -Pnexmark.args=--manageResources=false\n+    --monitorJobs=true\n+    --bigQueryTable=nexmark\n+    --bigQueryDataset=nexmark\n+    --project=apache-beam-testing\n+    --resourceNameMode=QUERY_RUNNER_AND_MODE\n+    --exportSummaryToBigQuery=true\n+    --tempLocation=gs://temp-storage-for-perf-tests/nexmark\n+    --influxDatabase=beam_test_metrics\n+    --influxHost=http://10.128.0.96:8086\n+    --baseInfluxMeasurement=nexmark\n+    --exportSummaryToInfluxDB=true\n+    --influxRetentionPolicy=forever\n+    --suite=SMOKE\n+    --enforceEncodability=true\n+    --enforceImmutability=true\n     --runner=DirectRunner\n   INFLUXDB_USER: ${{ secrets.INFLUXDB_USER }}\n   INFLUXDB_USER_PASSWORD: ${{ secrets.INFLUXDB_USER_PASSWORD }}\n@@ -112,4 +112,4 @@ jobs:\n           gradle-command: :sdks:java:testing:nexmark:run\n           arguments: |\n             -Pnexmark.runner=:runners:direct-java \\\n-            \"${{ env.GRADLE_COMMAND_ARGUMENTS }}--streaming=${{ matrix.streaming }}\"\n\\ No newline at end of file\n+            \"${{ env.GRADLE_COMMAND_ARGUMENTS }}--streaming=${{ matrix.streaming }}\"\n@@ -50,21 +50,21 @@ env:\n   GRADLE_ENTERPRISE_CACHE_USERNAME: ${{ secrets.GE_CACHE_USERNAME }}\n   GRADLE_ENTERPRISE_CACHE_PASSWORD: ${{ secrets.GE_CACHE_PASSWORD }}\n   GRADLE_COMMAND_ARGUMENTS: |\n-    -Pnexmark.args=--manageResources=false \n-    --monitorJobs=true \n-    --bigQueryTable=nexmark \n-    --bigQueryDataset=nexmark \n-    --project=apache-beam-testing \n-    --resourceNameMode=QUERY_RUNNER_AND_MODE \n-    --exportSummaryToBigQuery=true \n-    --tempLocation=gs://temp-storage-for-perf-tests/nexmark \n-    --influxDatabase=beam_test_metrics \n-    --influxHost=http://10.128.0.96:8086 \n-    --baseInfluxMeasurement=nexmark \n-    --exportSummaryToInfluxDB=true \n-    --influxRetentionPolicy=forever \n-    --suite=SMOKE \n-    --streamTimeout=60 \n+    -Pnexmark.args=--manageResources=false\n+    --monitorJobs=true\n+    --bigQueryTable=nexmark\n+    --bigQueryDataset=nexmark\n+    --project=apache-beam-testing\n+    --resourceNameMode=QUERY_RUNNER_AND_MODE\n+    --exportSummaryToBigQuery=true\n+    --tempLocation=gs://temp-storage-for-perf-tests/nexmark\n+    --influxDatabase=beam_test_metrics\n+    --influxHost=http://10.128.0.96:8086\n+    --baseInfluxMeasurement=nexmark\n+    --exportSummaryToInfluxDB=true\n+    --influxRetentionPolicy=forever\n+    --suite=SMOKE\n+    --streamTimeout=60\n     --runner=FlinkRunner\n   INFLUXDB_USER: ${{ secrets.INFLUXDB_USER }}\n   INFLUXDB_USER_PASSWORD: ${{ secrets.INFLUXDB_USER_PASSWORD }}\n@@ -50,21 +50,21 @@ env:\n   GRADLE_ENTERPRISE_CACHE_USERNAME: ${{ secrets.GE_CACHE_USERNAME }}\n   GRADLE_ENTERPRISE_CACHE_PASSWORD: ${{ secrets.GE_CACHE_PASSWORD }}\n   GRADLE_COMMAND_ARGUMENTS: |\n-    -Pnexmark.args=--manageResources=false \n-    --monitorJobs=true \n-    --bigQueryTable=nexmark \n-    --bigQueryDataset=nexmark \n-    --project=apache-beam-testing \n-    --resourceNameMode=QUERY_RUNNER_AND_MODE \n-    --exportSummaryToBigQuery=true \n-    --tempLocation=gs://temp-storage-for-perf-tests/nexmark \n-    --influxDatabase=beam_test_metrics \n-    --influxHost=http://10.128.0.96:8086 \n-    --baseInfluxMeasurement=nexmark \n-    --exportSummaryToInfluxDB=true \n-    --influxRetentionPolicy=forever \n-    --suite=SMOKE \n-    --streamTimeout=60 \n+    -Pnexmark.args=--manageResources=false\n+    --monitorJobs=true\n+    --bigQueryTable=nexmark\n+    --bigQueryDataset=nexmark\n+    --project=apache-beam-testing\n+    --resourceNameMode=QUERY_RUNNER_AND_MODE\n+    --exportSummaryToBigQuery=true\n+    --tempLocation=gs://temp-storage-for-perf-tests/nexmark\n+    --influxDatabase=beam_test_metrics\n+    --influxHost=http://10.128.0.96:8086\n+    --baseInfluxMeasurement=nexmark\n+    --exportSummaryToInfluxDB=true\n+    --influxRetentionPolicy=forever\n+    --suite=SMOKE\n+    --streamTimeout=60\n     --streaming=false\n   INFLUXDB_USER: ${{ secrets.INFLUXDB_USER }}\n   INFLUXDB_USER_PASSWORD: ${{ secrets.INFLUXDB_USER_PASSWORD }}\n@@ -111,4 +111,4 @@ jobs:\n           gradle-command: :sdks:java:testing:nexmark:run\n           arguments: |\n             -Pnexmark.runner=:runners:spark:3 \\\n-            \"${{ env.GRADLE_COMMAND_ARGUMENTS }}--runner=${{ matrix.runner }}\"\n\\ No newline at end of file\n+            \"${{ env.GRADLE_COMMAND_ARGUMENTS }}--runner=${{ matrix.runner }}\"\n@@ -56,7 +56,7 @@ jobs:\n     runs-on: [self-hosted, ubuntu-20.04, main]\n     timeout-minutes: 120\n     strategy:\n-      matrix: \n+      matrix:\n         job_name: [beam_PostCommit_Java_PVR_Flink_Streaming]\n         job_phrase: [Run Java Flink PortableValidatesRunner Streaming]\n     if: |\n@@ -56,7 +56,7 @@ jobs:\n     runs-on: [self-hosted, ubuntu-20.04, main]\n     timeout-minutes: 120\n     strategy:\n-      matrix: \n+      matrix:\n         job_name: [beam_PostCommit_Java_PVR_Samza]\n         job_phrase: [Run Java Samza PortableValidatesRunner]\n     if: |\n@@ -101,4 +101,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -56,7 +56,7 @@ jobs:\n     runs-on: [self-hosted, ubuntu-20.04, main]\n     timeout-minutes: 180\n     strategy:\n-      matrix: \n+      matrix:\n         job_name: [beam_PostCommit_Java_PVR_Spark3_Streaming]\n         job_phrase: [Run Java Spark v3 PortableValidatesRunner Streaming]\n     if: |\n@@ -91,4 +91,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -56,7 +56,7 @@ jobs:\n     runs-on: [self-hosted, ubuntu-20.04, main]\n     timeout-minutes: 240\n     strategy:\n-      matrix: \n+      matrix:\n         job_name: [beam_PostCommit_Java_PVR_Spark_Batch]\n         job_phrase: [Run Java Spark PortableValidatesRunner Batch]\n     if: |\n@@ -57,7 +57,7 @@ jobs:\n     timeout-minutes: 100\n     strategy:\n       fail-fast: false\n-      matrix: \n+      matrix:\n         job_name: [beam_PostCommit_Java_SingleStoreIO_IT]\n         job_phrase: [Run Java SingleStoreIO_IT]\n     if: |\n@@ -83,7 +83,7 @@ jobs:\n           k8s_namespace: ${{ matrix.job_name }}-${{ github.run_id }}\n           remove_finalizer:  memsqlclusters.memsql.com/sdb-cluster\n       - name: Install SingleStore operator\n-        run: | \n+        run: |\n           kubectl apply -f ${{github.workspace}}/.test-infra/kubernetes/singlestore/sdb-rbac.yaml\n           kubectl apply -f ${{github.workspace}}/.test-infra/kubernetes/singlestore/sdb-cluster-crd.yaml\n           kubectl apply -f ${{github.workspace}}/.test-infra/kubernetes/singlestore/sdb-operator.yaml\n@@ -94,7 +94,7 @@ jobs:\n           kubectl apply -f ${{github.workspace}}/.test-infra/kubernetes/singlestore/sdb-cluster.yaml\n           kubectl wait --for=jsonpath='{.status.phase}'=Running memsqlclusters.memsql.com --all --timeout=300s\n           kubectl wait svc/svc-sdb-cluster-ddl --for=jsonpath='{.status.loadBalancer.ingress[0].ip}' --timeout=300s\n-          loadbalancer_IP=$(kubectl get svc svc-sdb-cluster-ddl -o jsonpath='{.status.loadBalancer.ingress[0].ip}') \n+          loadbalancer_IP=$(kubectl get svc svc-sdb-cluster-ddl -o jsonpath='{.status.loadBalancer.ingress[0].ip}')\n           echo lb_ip=$loadbalancer_IP >> $GITHUB_OUTPUT\n       - name: Run Java SingleStore IO IT\n         uses: ./.github/actions/gradle-command-self-hosted-action\n@@ -48,33 +48,33 @@ env:\n   GRADLE_ENTERPRISE_CACHE_USERNAME: ${{ secrets.GE_CACHE_USERNAME }}\n   GRADLE_ENTERPRISE_CACHE_PASSWORD: ${{ secrets.GE_CACHE_PASSWORD }}\n   GRADLE_COMMAND_ARGUMENTS: |\n-    --runner=DataflowRunner \n-    --region=us-central1 \n-    --numWorkers=4 \n-    --maxNumWorkers=4 \n-    --autoscalingAlgorithm=NONE \n-    --dataSize=1GB \n-    --sourceType=PARQUET \n-    --dataDirectory=gs://beam-tpcds/datasets/parquet/nonpartitioned \n-    --resultsDirectory=gs://beam-tpcds/results/dataflow/ \n+    --runner=DataflowRunner\n+    --region=us-central1\n+    --numWorkers=4\n+    --maxNumWorkers=4\n+    --autoscalingAlgorithm=NONE\n+    --dataSize=1GB\n+    --sourceType=PARQUET\n+    --dataDirectory=gs://beam-tpcds/datasets/parquet/nonpartitioned\n+    --resultsDirectory=gs://beam-tpcds/results/dataflow/\n     --tpcParallel=1\n   INFLUXDB_USER: ${{ secrets.INFLUXDB_USER }}\n   INFLUXDB_USER_PASSWORD: ${{ secrets.INFLUXDB_USER_PASSWORD }}\n   tpcdsBigQueryArgs: |\n-    --bigQueryTable=tpcds \n-    --bigQueryDataset=tpcds \n-    --project=apache-beam-testing \n-    --resourceNameMode=QUERY_RUNNER_AND_MODE \n-    --exportSummaryToBigQuery=true \n-    --tempLocation=gs://temp-storage-for-perf-tests/tpcds \n+    --bigQueryTable=tpcds\n+    --bigQueryDataset=tpcds\n+    --project=apache-beam-testing\n+    --resourceNameMode=QUERY_RUNNER_AND_MODE\n+    --exportSummaryToBigQuery=true\n+    --tempLocation=gs://temp-storage-for-perf-tests/tpcds\n   tpcdsInfluxDBArgs: |\n-    --influxDatabase=beam_test_metrics \n-    --influxHost=http://10.128.0.96:8086 \n-    --baseInfluxMeasurement=tpcds \n-    --exportSummaryToInfluxDB=true \n-    --influxRetentionPolicy=forever \n+    --influxDatabase=beam_test_metrics\n+    --influxHost=http://10.128.0.96:8086\n+    --baseInfluxMeasurement=tpcds\n+    --exportSummaryToInfluxDB=true\n+    --influxRetentionPolicy=forever\n   tpcdsQueriesArg: 3,7,10,25,26,29,35,38,40,42,43,52,55,69,79,83,84,87,93,96\n-    \n+\n jobs:\n   beam_PostCommit_Java_Tpcds_Dataflow:\n     if: |\n@@ -58,20 +58,20 @@ env:\n   INFLUXDB_USER: ${{ secrets.INFLUXDB_USER }}\n   INFLUXDB_USER_PASSWORD: ${{ secrets.INFLUXDB_USER_PASSWORD }}\n   tpcdsBigQueryArgs: |\n-    --bigQueryTable=tpcds \n-    --bigQueryDataset=tpcds \n-    --project=apache-beam-testing \n-    --resourceNameMode=QUERY_RUNNER_AND_MODE \n-    --exportSummaryToBigQuery=true \n-    --tempLocation=gs://temp-storage-for-perf-tests/tpcds \n+    --bigQueryTable=tpcds\n+    --bigQueryDataset=tpcds\n+    --project=apache-beam-testing\n+    --resourceNameMode=QUERY_RUNNER_AND_MODE\n+    --exportSummaryToBigQuery=true\n+    --tempLocation=gs://temp-storage-for-perf-tests/tpcds\n   tpcdsInfluxDBArgs: |\n-    --influxDatabase=beam_test_metrics \n-    --influxHost=http://10.128.0.96:8086 \n-    --baseInfluxMeasurement=tpcds \n-    --exportSummaryToInfluxDB=true \n-    --influxRetentionPolicy=forever \n+    --influxDatabase=beam_test_metrics\n+    --influxHost=http://10.128.0.96:8086\n+    --baseInfluxMeasurement=tpcds\n+    --exportSummaryToInfluxDB=true\n+    --influxRetentionPolicy=forever\n   tpcdsQueriesArg: 3,7,10,25,26,29,35,38,40,42,43,52,55,69,79,83,84,87,93,96\n-    \n+\n jobs:\n   beam_PostCommit_Java_Tpcds_Flink:\n     if: |\n@@ -56,20 +56,20 @@ env:\n   INFLUXDB_USER: ${{ secrets.INFLUXDB_USER }}\n   INFLUXDB_USER_PASSWORD: ${{ secrets.INFLUXDB_USER_PASSWORD }}\n   tpcdsBigQueryArgs: |\n-    --bigQueryTable=tpcds \n-    --bigQueryDataset=tpcds \n-    --project=apache-beam-testing \n-    --resourceNameMode=QUERY_RUNNER_AND_MODE \n-    --exportSummaryToBigQuery=true \n-    --tempLocation=gs://temp-storage-for-perf-tests/tpcds \n+    --bigQueryTable=tpcds\n+    --bigQueryDataset=tpcds\n+    --project=apache-beam-testing\n+    --resourceNameMode=QUERY_RUNNER_AND_MODE\n+    --exportSummaryToBigQuery=true\n+    --tempLocation=gs://temp-storage-for-perf-tests/tpcds\n   tpcdsInfluxDBArgs: |\n-    --influxDatabase=beam_test_metrics \n-    --influxHost=http://10.128.0.96:8086 \n-    --baseInfluxMeasurement=tpcds \n-    --exportSummaryToInfluxDB=true \n-    --influxRetentionPolicy=forever \n+    --influxDatabase=beam_test_metrics\n+    --influxHost=http://10.128.0.96:8086\n+    --baseInfluxMeasurement=tpcds\n+    --exportSummaryToInfluxDB=true\n+    --influxRetentionPolicy=forever\n   tpcdsQueriesArg: 3,7,10,25,26,29,35,38,40,42,43,52,55,69,79,83,84,87,93,96\n-    \n+\n jobs:\n   beam_PostCommit_Java_Tpcds_Spark:\n     if: |\n@@ -94,4 +94,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -101,4 +101,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -94,4 +94,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -94,4 +94,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -94,4 +94,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -91,4 +91,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -100,4 +100,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -49,7 +49,7 @@ env:\n   GRADLE_ENTERPRISE_CACHE_PASSWORD: ${{ secrets.GE_CACHE_PASSWORD }}\n \n jobs:\n-  beam_PostCommit_Java_ValidatesRunner_Flink:    \n+  beam_PostCommit_Java_ValidatesRunner_Flink:\n     name: ${{ matrix.job_name }} (${{ matrix.job_phrase }})\n     runs-on: [self-hosted, ubuntu-20.04, main]\n     timeout-minutes: 100\n@@ -49,7 +49,7 @@ env:\n   GRADLE_ENTERPRISE_CACHE_PASSWORD: ${{ secrets.GE_CACHE_PASSWORD }}\n \n jobs:\n-  beam_PostCommit_Java_ValidatesRunner_Samza:    \n+  beam_PostCommit_Java_ValidatesRunner_Samza:\n     name: ${{ matrix.job_name }} (${{ matrix.job_phrase }})\n     runs-on: [self-hosted, ubuntu-20.04, main]\n     timeout-minutes: 100\n@@ -97,4 +97,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -49,7 +49,7 @@ env:\n   GRADLE_ENTERPRISE_CACHE_PASSWORD: ${{ secrets.GE_CACHE_PASSWORD }}\n \n jobs:\n-  beam_PostCommit_Java_ValidatesRunner_Spark:    \n+  beam_PostCommit_Java_ValidatesRunner_Spark:\n     name: ${{ matrix.job_name }} (${{ matrix.job_phrase }})\n     runs-on: [self-hosted, ubuntu-20.04, main]\n     timeout-minutes: 120\n@@ -91,4 +91,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -49,7 +49,7 @@ env:\n   GRADLE_ENTERPRISE_CACHE_PASSWORD: ${{ secrets.GE_CACHE_PASSWORD }}\n \n jobs:\n-  beam_PostCommit_Java_ValidatesRunner_SparkStructuredStreaming:    \n+  beam_PostCommit_Java_ValidatesRunner_SparkStructuredStreaming:\n     name: ${{ matrix.job_name }} (${{ matrix.job_phrase }})\n     runs-on: [self-hosted, ubuntu-20.04, main]\n     timeout-minutes: 120\n@@ -91,4 +91,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -99,4 +99,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -49,7 +49,7 @@ env:\n   GRADLE_ENTERPRISE_CACHE_PASSWORD: ${{ secrets.GE_CACHE_PASSWORD }}\n \n jobs:\n-  beam_PostCommit_Java_ValidatesRunner_Twister2:    \n+  beam_PostCommit_Java_ValidatesRunner_Twister2:\n     name: ${{ matrix.job_name }} (${{ matrix.job_phrase }})\n     runs-on: [self-hosted, ubuntu-20.04, main]\n     timeout-minutes: 120\n@@ -91,4 +91,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -49,7 +49,7 @@ env:\n   GRADLE_ENTERPRISE_CACHE_PASSWORD: ${{ secrets.GE_CACHE_PASSWORD }}\n \n jobs:\n-  beam_PostCommit_Java_ValidatesRunner_ULR:    \n+  beam_PostCommit_Java_ValidatesRunner_ULR:\n     name: ${{ matrix.job_name }} (${{ matrix.job_phrase }})\n     runs-on: [self-hosted, ubuntu-20.04, main]\n     timeout-minutes: 180\n@@ -90,4 +90,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -90,4 +90,4 @@ jobs:\n         uses: actions/upload-artifact@v4\n         with:\n           name: Javadoc Results\n-          path: '**/sdks/java/javadoc/build/docs/javadoc/**'\n\\ No newline at end of file\n+          path: '**/sdks/java/javadoc/build/docs/javadoc/**'\n@@ -95,4 +95,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/pytest*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -95,4 +95,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/pytest*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -132,4 +132,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/pytest*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -95,4 +95,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/pytest*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -102,4 +102,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/pytest*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -102,4 +102,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/pytest*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -94,4 +94,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/pytest*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -136,4 +136,4 @@ jobs:\n             -PpythonVersion=3.9 \\\n             \"-Pnexmark.args=${{ env.GRADLE_PYTHON_COMMAND_ARGUMENTS }} \\\n             --query=${{ matrix.query }} \\\n-            --input=gs://temp-storage-for-perf-tests/nexmark/eventFiles/beam_PostCommit_Python_Nexmark_Direct/query${{ matrix.query }}-\\*\"\n\\ No newline at end of file\n+            --input=gs://temp-storage-for-perf-tests/nexmark/eventFiles/beam_PostCommit_Python_Nexmark_Direct/query${{ matrix.query }}-\\*\"\n@@ -118,4 +118,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/pytest*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -110,4 +110,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/pytest*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -104,4 +104,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/pytest*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -107,4 +107,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/pytest*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -102,4 +102,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/pytest*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -95,4 +95,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/pytest*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -96,4 +96,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/pytest*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -94,4 +94,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/pytest*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -99,4 +99,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/pytest*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -75,5 +75,5 @@ jobs:\n       - name: run PostCommit Website Test script\n         uses: ./.github/actions/gradle-command-self-hosted-action\n         with:\n-          gradle-command: :website:testWebsite \n-          arguments: -PdisableExternal=false\n\\ No newline at end of file\n+          gradle-command: :website:testWebsite\n+          arguments: -PdisableExternal=false\n@@ -97,4 +97,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -96,4 +96,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -93,4 +93,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/pytest*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -96,4 +96,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/pytest*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -104,4 +104,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -97,4 +97,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -95,4 +95,3 @@ jobs:\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/pytest*.xml'\n           large_files: true\n-\n@@ -95,4 +95,4 @@ jobs:\n         with:\n           gradle-command: :communityMetricsPreCommit\n           arguments: |\n-            -PKUBE_CONFIG_PATH='$HOME/.kube/config'\n\\ No newline at end of file\n+            -PKUBE_CONFIG_PATH='$HOME/.kube/config'\n@@ -86,4 +86,4 @@ jobs:\n     - name: run GHA PreCommit script\n       uses: ./.github/actions/gradle-command-self-hosted-action\n       with:\n-        gradle-command: :beam-test-gha:preCommit\n\\ No newline at end of file\n+        gradle-command: :beam-test-gha:preCommit\n@@ -86,4 +86,4 @@ jobs:\n       - name: run goPreCommit script\n         uses: ./.github/actions/gradle-command-self-hosted-action\n         with:\n-          gradle-command: :goPreCommit\n\\ No newline at end of file\n+          gradle-command: :goPreCommit\n@@ -86,4 +86,4 @@ jobs:\n       - name: Run goPortablePreCommit script\n         uses: ./.github/actions/gradle-command-self-hosted-action\n         with:\n-          gradle-command: :goPortablePreCommit\n\\ No newline at end of file\n+          gradle-command: :goPortablePreCommit\n@@ -86,4 +86,4 @@ jobs:\n       - name: Run goPrismPreCommit script\n         uses: ./.github/actions/gradle-command-self-hosted-action\n         with:\n-          gradle-command: :goPrismPreCommit\n\\ No newline at end of file\n+          gradle-command: :goPrismPreCommit\n@@ -102,4 +102,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -142,4 +142,4 @@ jobs:\n         if: always()\n         with:\n           name: Publish SpotBugs\n-          path: '**/build/reports/spotbugs/*.html'\n\\ No newline at end of file\n+          path: '**/build/reports/spotbugs/*.html'\n@@ -116,4 +116,4 @@ jobs:\n         if: always()\n         with:\n           name: Publish SpotBugs\n-          path: '**/build/reports/spotbugs/*.html'\n\\ No newline at end of file\n+          path: '**/build/reports/spotbugs/*.html'\n@@ -135,4 +135,4 @@ jobs:\n         if: always()\n         with:\n           name: Publish SpotBugs\n-          path: '**/build/reports/spotbugs/*.html'\n\\ No newline at end of file\n+          path: '**/build/reports/spotbugs/*.html'\n@@ -117,4 +117,4 @@ jobs:\n         if: always()\n         with:\n           name: Publish SpotBugs\n-          path: '**/build/reports/spotbugs/*.html'\n\\ No newline at end of file\n+          path: '**/build/reports/spotbugs/*.html'\n@@ -121,4 +121,4 @@ jobs:\n         if: always()\n         with:\n           name: Publish SpotBugs\n-          path: '**/build/reports/spotbugs/*.html'\n\\ No newline at end of file\n+          path: '**/build/reports/spotbugs/*.html'\n@@ -117,4 +117,4 @@ jobs:\n         if: always()\n         with:\n           name: Publish SpotBugs\n-          path: '**/build/reports/spotbugs/*.html'\n\\ No newline at end of file\n+          path: '**/build/reports/spotbugs/*.html'\n@@ -117,4 +117,4 @@ jobs:\n         if: always()\n         with:\n           name: Publish SpotBugs\n-          path: '**/build/reports/spotbugs/*.html'\n\\ No newline at end of file\n+          path: '**/build/reports/spotbugs/*.html'\n@@ -129,4 +129,4 @@ jobs:\n         if: always()\n         with:\n           name: Publish SpotBugs\n-          path: '**/build/reports/spotbugs/*.html'\n\\ No newline at end of file\n+          path: '**/build/reports/spotbugs/*.html'\n@@ -118,4 +118,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -138,4 +138,4 @@ jobs:\n       uses: actions/upload-artifact@v4\n       with:\n         name: SpotBugs Results\n-        path: '**/build/reports/spotbugs/*.html'\n\\ No newline at end of file\n+        path: '**/build/reports/spotbugs/*.html'\n@@ -118,4 +118,4 @@ jobs:\n         if: always()\n         with:\n           name: Publish SpotBugs\n-          path: '**/build/reports/spotbugs/*.html'\n\\ No newline at end of file\n+          path: '**/build/reports/spotbugs/*.html'\n@@ -105,4 +105,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -153,4 +153,4 @@ jobs:\n         uses: codecov/codecov-action@v3\n         with:\n           file: ${{ steps.jacoco_report_path.outputs.path }}\n-          flags: java\n\\ No newline at end of file\n+          flags: java\n@@ -115,4 +115,4 @@ jobs:\n       if: always()\n       with:\n         name: Publish SpotBugs\n-        path: '**/build/reports/spotbugs/*.html'\n\\ No newline at end of file\n+        path: '**/build/reports/spotbugs/*.html'\n@@ -119,4 +119,4 @@ jobs:\n         if: always()\n         with:\n           name: Publish SpotBugs\n-          path: '**/build/reports/spotbugs/*.html'\n\\ No newline at end of file\n+          path: '**/build/reports/spotbugs/*.html'\n@@ -134,4 +134,4 @@ jobs:\n         if: always()\n         with:\n           name: Publish SpotBugs\n-          path: '**/build/reports/spotbugs/*.html'\n\\ No newline at end of file\n+          path: '**/build/reports/spotbugs/*.html'\n@@ -157,4 +157,4 @@ jobs:\n         if: always()\n         with:\n           name: Publish SpotBugs\n-          path: '**/build/reports/spotbugs/*.html'\n\\ No newline at end of file\n+          path: '**/build/reports/spotbugs/*.html'\n@@ -134,4 +134,4 @@ jobs:\n         if: always()\n         with:\n           name: Publish SpotBugs\n-          path: '**/build/reports/spotbugs/*.html'\n\\ No newline at end of file\n+          path: '**/build/reports/spotbugs/*.html'\n@@ -117,4 +117,4 @@ jobs:\n         if: always()\n         with:\n           name: Publish SpotBugs\n-          path: '**/build/reports/spotbugs/*.html'\n\\ No newline at end of file\n+          path: '**/build/reports/spotbugs/*.html'\n@@ -124,4 +124,4 @@ jobs:\n         if: always()\n         with:\n           name: Publish SpotBugs\n-          path: '**/build/reports/spotbugs/*.html'\n\\ No newline at end of file\n+          path: '**/build/reports/spotbugs/*.html'\n@@ -124,4 +124,4 @@ jobs:\n         if: always()\n         with:\n           name: Publish SpotBugs\n-          path: '**/build/reports/spotbugs/*.html'\n\\ No newline at end of file\n+          path: '**/build/reports/spotbugs/*.html'\n@@ -117,4 +117,4 @@ jobs:\n         if: always()\n         with:\n           name: Publish SpotBugs\n-          path: '**/build/reports/spotbugs/*.html'\n\\ No newline at end of file\n+          path: '**/build/reports/spotbugs/*.html'\n@@ -117,4 +117,4 @@ jobs:\n         if: always()\n         with:\n           name: Publish SpotBugs\n-          path: '**/build/reports/spotbugs/*.html'\n\\ No newline at end of file\n+          path: '**/build/reports/spotbugs/*.html'\n@@ -117,4 +117,4 @@ jobs:\n         if: always()\n         with:\n           name: Publish SpotBugs\n-          path: '**/build/reports/spotbugs/*.html'\n\\ No newline at end of file\n+          path: '**/build/reports/spotbugs/*.html'\n@@ -126,4 +126,4 @@ jobs:\n         if: always()\n         with:\n           name: Publish SpotBugs\n-          path: '**/build/reports/spotbugs/*.html'\n\\ No newline at end of file\n+          path: '**/build/reports/spotbugs/*.html'\n@@ -117,4 +117,4 @@ jobs:\n         if: always()\n         with:\n           name: Publish SpotBugs\n-          path: '**/build/reports/spotbugs/*.html'\n\\ No newline at end of file\n+          path: '**/build/reports/spotbugs/*.html'\n@@ -135,4 +135,4 @@ jobs:\n         if: always()\n         with:\n           name: Publish SpotBugs\n-          path: '**/build/reports/spotbugs/*.html'\n\\ No newline at end of file\n+          path: '**/build/reports/spotbugs/*.html'\n@@ -117,4 +117,4 @@ jobs:\n         if: always()\n         with:\n           name: Publish SpotBugs\n-          path: '**/build/reports/spotbugs/*.html'\n\\ No newline at end of file\n+          path: '**/build/reports/spotbugs/*.html'\n@@ -117,4 +117,4 @@ jobs:\n         if: always()\n         with:\n           name: Publish SpotBugs\n-          path: '**/build/reports/spotbugs/*.html'\n\\ No newline at end of file\n+          path: '**/build/reports/spotbugs/*.html'\n@@ -115,4 +115,4 @@ jobs:\n       if: always()\n       with:\n         name: Publish SpotBugs\n-        path: '**/build/reports/spotbugs/*.html'\n\\ No newline at end of file\n+        path: '**/build/reports/spotbugs/*.html'\n@@ -119,4 +119,4 @@ jobs:\n         if: always()\n         with:\n           name: Publish SpotBugs\n-          path: '**/build/reports/spotbugs/*.html'\n\\ No newline at end of file\n+          path: '**/build/reports/spotbugs/*.html'\n@@ -128,4 +128,4 @@ jobs:\n         if: always()\n         with:\n           name: Publish SpotBugs\n-          path: '**/build/reports/spotbugs/*.html'\n\\ No newline at end of file\n+          path: '**/build/reports/spotbugs/*.html'\n@@ -124,4 +124,4 @@ jobs:\n       if: always()\n       with:\n         name: Publish SpotBugs\n-        path: '**/build/reports/spotbugs/*.html'\n\\ No newline at end of file\n+        path: '**/build/reports/spotbugs/*.html'\n@@ -117,4 +117,4 @@ jobs:\n         if: always()\n         with:\n           name: Publish SpotBugs\n-          path: '**/build/reports/spotbugs/*.html'\n\\ No newline at end of file\n+          path: '**/build/reports/spotbugs/*.html'\n@@ -106,4 +106,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/build/test-results/**/*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -117,4 +117,4 @@ jobs:\n         if: always()\n         with:\n           name: Publish SpotBugs\n-          path: '**/build/reports/spotbugs/*.html'\n\\ No newline at end of file\n+          path: '**/build/reports/spotbugs/*.html'\n@@ -117,4 +117,4 @@ jobs:\n         if: always()\n         with:\n           name: Publish SpotBugs\n-          path: '**/build/reports/spotbugs/*.html'\n\\ No newline at end of file\n+          path: '**/build/reports/spotbugs/*.html'\n@@ -117,4 +117,4 @@ jobs:\n         if: always()\n         with:\n           name: Publish SpotBugs\n-          path: '**/build/reports/spotbugs/*.html'\n\\ No newline at end of file\n+          path: '**/build/reports/spotbugs/*.html'\n@@ -102,4 +102,4 @@ jobs:\n       - name: run Kotlin Examples script\n         uses: ./.github/actions/gradle-command-self-hosted-action\n         with:\n-          gradle-command: :examples:kotlin:preCommit\n\\ No newline at end of file\n+          gradle-command: :examples:kotlin:preCommit\n@@ -112,4 +112,4 @@ jobs:\n       - name: run Portable Python script\n         uses: ./.github/actions/gradle-command-self-hosted-action\n         with:\n-          gradle-command: :sdks:python:test-suites:portable:py${{steps.set_py_ver_clean.outputs.py_ver_clean}}:preCommitPy${{steps.set_py_ver_clean.outputs.py_ver_clean}}\n\\ No newline at end of file\n+          gradle-command: :sdks:python:test-suites:portable:py${{steps.set_py_ver_clean.outputs.py_ver_clean}}:preCommitPy${{steps.set_py_ver_clean.outputs.py_ver_clean}}\n@@ -106,4 +106,4 @@ jobs:\n       - name: run Prism Python Validates Runner script\n         uses: ./.github/actions/gradle-command-self-hosted-action\n         with:\n-          gradle-command: :sdks:python:test-suites:portable:py${{steps.set_py_ver_clean.outputs.py_ver_clean}}:prismValidatesRunner\n\\ No newline at end of file\n+          gradle-command: :sdks:python:test-suites:portable:py${{steps.set_py_ver_clean.outputs.py_ver_clean}}:prismValidatesRunner\n@@ -110,4 +110,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/pytest*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -105,4 +105,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/pytest*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -110,4 +110,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/pytest*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -110,4 +110,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/pytest*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -117,4 +117,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/pytest*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -122,4 +122,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/pytest*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -110,4 +110,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/pytest*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -111,4 +111,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/pytest*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -129,4 +129,4 @@ jobs:\n         uses: codecov/codecov-action@v3\n         with:\n           file: ${{ steps.jacoco_report_path.outputs.path }}\n-          flags: java\n\\ No newline at end of file\n+          flags: java\n@@ -122,4 +122,4 @@ jobs:\n         if: always()\n         with:\n           name: Publish SpotBugs\n-          path: '**/build/reports/spotbugs/*.html'\n\\ No newline at end of file\n+          path: '**/build/reports/spotbugs/*.html'\n@@ -126,4 +126,4 @@ jobs:\n         if: always()\n         with:\n           name: Publish SpotBugs\n-          path: '**/build/reports/spotbugs/*.html'\n\\ No newline at end of file\n+          path: '**/build/reports/spotbugs/*.html'\n@@ -99,4 +99,4 @@ jobs:\n         uses: jwgmeligmeyling/checkstyle-github-action@v1\n         if: always()\n         with:\n-          path: '**/build/reports/checkstyle/*.xml'\n\\ No newline at end of file\n+          path: '**/build/reports/checkstyle/*.xml'\n@@ -30,7 +30,7 @@ on:\n   schedule:\n     - cron: '15 3/6 * * *'\n   workflow_dispatch:\n-  \n+\n   # This allows a subsequently queued workflow run to interrupt previous runs\n concurrency:\n   group: '${{ github.workflow }} @ ${{ github.event.issue.number || github.event.pull_request.head.label || github.sha || github.head_ref || github.ref }}-${{ github.event.schedule || github.event.comment.id || github.event.sender.login }}'\n@@ -87,4 +87,4 @@ jobs:\n       - name: run typescriptPreCommit script\n         uses: ./.github/actions/gradle-command-self-hosted-action\n         with:\n-          gradle-command: :typescriptPreCommit\n\\ No newline at end of file\n+          gradle-command: :typescriptPreCommit\n@@ -85,4 +85,4 @@ jobs:\n       - name: run websitePreCommit script\n         uses: ./.github/actions/gradle-command-self-hosted-action\n         with:\n-          gradle-command: :websitePreCommit\n\\ No newline at end of file\n+          gradle-command: :websitePreCommit\n@@ -13,7 +13,7 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n \n-name: PreCommit Website Stage GCS  \n+name: PreCommit Website Stage GCS\n \n on:\n   push:\n@@ -38,7 +38,7 @@ env:\n   DEVELOCITY_ACCESS_KEY: ${{ secrets.DEVELOCITY_ACCESS_KEY }}\n   GRADLE_ENTERPRISE_CACHE_USERNAME: ${{ secrets.GE_CACHE_USERNAME }}\n   GRADLE_ENTERPRISE_CACHE_PASSWORD: ${{ secrets.GE_CACHE_PASSWORD }}\n-  gcsbucket: apache-beam-website-pull-requests  \n+  gcsbucket: apache-beam-website-pull-requests\n   ghprbPullId:\n \n #Setting explicit permissions for the action to avoid the default permissions which are `write-all` in case of pull_request_target event\n@@ -105,4 +105,4 @@ jobs:\n           commit: '${{ env.prsha || env.GITHUB_SHA }}'\n           comment_mode: ${{ github.event_name == 'issue_comment'  && 'always' || 'off' }}\n           files: '**/pytest*.xml'\n-          large_files: true\n\\ No newline at end of file\n+          large_files: true\n@@ -76,4 +76,4 @@ jobs:\n         with:\n           gradle-command: :communityMetricsProber\n           arguments: |\n-            --rerun-tasks\n\\ No newline at end of file\n+            --rerun-tasks\n@@ -86,4 +86,4 @@ jobs:\n           gradle-command: :runners:flink:1.17:job-server-container:dockerPush\n           arguments: |\n             -Pdocker-repository-root=gcr.io/apache-beam-testing/beam_portability \\\n-            -Pdocker-tag-list=latest\n\\ No newline at end of file\n+            -Pdocker-tag-list=latest\n@@ -104,4 +104,4 @@ jobs:\n             -Prunner=DataflowRunner \\\n             -PpythonVersion=3.10 \\\n             -PloadTest.requirementsTxtFile=apache_beam/ml/inference/tensorflow_tests_requirements.txt \\\n-            '-PloadTest.args=${{ env.beam_Python_Cost_Benchmarks_Dataflow_test_arguments_2 }} --job_name=benchmark-tests-tf-mnist-classification-python-${{env.NOW_UTC}} --input_file=gs://apache-beam-ml/testing/inputs/it_mnist_data.csv --output_file=gs://temp-storage-for-end-to-end-tests/inference/result_tf_mnist-${{env.NOW_UTC}}.txt --model=gs://apache-beam-ml/models/tensorflow/mnist/' \\\n\\ No newline at end of file\n+            '-PloadTest.args=${{ env.beam_Python_Cost_Benchmarks_Dataflow_test_arguments_2 }} --job_name=benchmark-tests-tf-mnist-classification-python-${{env.NOW_UTC}} --input_file=gs://apache-beam-ml/testing/inputs/it_mnist_data.csv --output_file=gs://temp-storage-for-end-to-end-tests/inference/result_tf_mnist-${{env.NOW_UTC}}.txt --model=gs://apache-beam-ml/models/tensorflow/mnist/' \\\n@@ -77,4 +77,4 @@ jobs:\n         run: |\n           bash sdks/python/scripts/run_snapshot_publish.sh\n         env:\n-          WORKSPACE: ${{ github.workspace }}\n\\ No newline at end of file\n+          WORKSPACE: ${{ github.workspace }}\n@@ -74,4 +74,4 @@ jobs:\n       - name: run BigQuery StressTest Large\n         uses: ./.github/actions/gradle-command-self-hosted-action\n         with:\n-          gradle-command: :it:google-cloud-platform:BigQueryStressTestLarge --info -DinfluxHost=\"http://10.128.0.96:8086\" -DinfluxDatabase=\"beam_test_metrics\" -DinfluxMeasurement=\"java_stress_test_bigquery\"\n\\ No newline at end of file\n+          gradle-command: :it:google-cloud-platform:BigQueryStressTestLarge --info -DinfluxHost=\"http://10.128.0.96:8086\" -DinfluxDatabase=\"beam_test_metrics\" -DinfluxMeasurement=\"java_stress_test_bigquery\"\n@@ -74,4 +74,4 @@ jobs:\n       - name: run BigTable StressTest Large\n         uses: ./.github/actions/gradle-command-self-hosted-action\n         with:\n-          gradle-command: :it:google-cloud-platform:BigTableStressTestLarge --info -DinfluxHost=\"http://10.128.0.96:8086\" -DinfluxDatabase=\"beam_test_metrics\" -DinfluxMeasurement=\"java_stress_test_bigtable\"\n\\ No newline at end of file\n+          gradle-command: :it:google-cloud-platform:BigTableStressTestLarge --info -DinfluxHost=\"http://10.128.0.96:8086\" -DinfluxDatabase=\"beam_test_metrics\" -DinfluxMeasurement=\"java_stress_test_bigtable\"\n@@ -97,4 +97,4 @@ jobs:\n       - name: run Kafka StressTest Large\n         uses: ./.github/actions/gradle-command-self-hosted-action\n         with:\n-          gradle-command: :it:kafka:KafkaStressTestLarge --info -DbootstrapServers=\"${{ steps.set_brokers.outputs.KAFKA_SERVICE_BROKER_0 }}:${{ steps.set_brokers.outputs.KAFKA_SERVICE_BROKER_PORTS_0 }},${{ steps.set_brokers.outputs.KAFKA_SERVICE_BROKER_1 }}:${{ steps.set_brokers.outputs.KAFKA_SERVICE_BROKER_PORTS_1 }},${{ steps.set_brokers.outputs.KAFKA_SERVICE_BROKER_2 }}:${{ steps.set_brokers.outputs.KAFKA_SERVICE_BROKER_PORTS_2 }}\" -DinfluxHost=\"http://10.128.0.96:8086\" -DinfluxDatabase=\"beam_test_metrics\" -DinfluxMeasurement=\"java_stress_test_kafka\"\n\\ No newline at end of file\n+          gradle-command: :it:kafka:KafkaStressTestLarge --info -DbootstrapServers=\"${{ steps.set_brokers.outputs.KAFKA_SERVICE_BROKER_0 }}:${{ steps.set_brokers.outputs.KAFKA_SERVICE_BROKER_PORTS_0 }},${{ steps.set_brokers.outputs.KAFKA_SERVICE_BROKER_1 }}:${{ steps.set_brokers.outputs.KAFKA_SERVICE_BROKER_PORTS_1 }},${{ steps.set_brokers.outputs.KAFKA_SERVICE_BROKER_2 }}:${{ steps.set_brokers.outputs.KAFKA_SERVICE_BROKER_PORTS_2 }}\" -DinfluxHost=\"http://10.128.0.96:8086\" -DinfluxDatabase=\"beam_test_metrics\" -DinfluxMeasurement=\"java_stress_test_kafka\"\n@@ -74,4 +74,4 @@ jobs:\n       - name: run PubSub StressTest Large\n         uses: ./.github/actions/gradle-command-self-hosted-action\n         with:\n-          gradle-command: :it:google-cloud-platform:PubSubStressTestLarge --info -DinfluxHost=\"http://10.128.0.96:8086\" -DinfluxDatabase=\"beam_test_metrics\" -DinfluxMeasurement=\"java_stress_test_pubsub\"\n\\ No newline at end of file\n+          gradle-command: :it:google-cloud-platform:PubSubStressTestLarge --info -DinfluxHost=\"http://10.128.0.96:8086\" -DinfluxDatabase=\"beam_test_metrics\" -DinfluxMeasurement=\"java_stress_test_pubsub\"\n@@ -74,4 +74,4 @@ jobs:\n       - name: run Spanner StressTest Large\n         uses: ./.github/actions/gradle-command-self-hosted-action\n         with:\n-          gradle-command: :it:google-cloud-platform:SpannerStressTestLarge --info -DinfluxHost=\"http://10.128.0.96:8086\" -DinfluxDatabase=\"beam_test_metrics\" -DinfluxMeasurement=\"java_stress_test_spanner\"\n\\ No newline at end of file\n+          gradle-command: :it:google-cloud-platform:SpannerStressTestLarge --info -DinfluxHost=\"http://10.128.0.96:8086\" -DinfluxDatabase=\"beam_test_metrics\" -DinfluxMeasurement=\"java_stress_test_spanner\"\n@@ -93,7 +93,7 @@ jobs:\n           echo \"version=$VERSION\" >> $GITHUB_OUTPUT\n           echo \"name=$NAME\" >> $GITHUB_OUTPUT\n           echo \"pluginVerifierHomeDir=~/.pluginVerifier\" >> $GITHUB_OUTPUT\n-          \n+\n           echo \"changelog<<EOF\" >> $GITHUB_OUTPUT\n           echo \"$CHANGELOG\" >> $GITHUB_OUTPUT\n           echo \"EOF\" >> $GITHUB_OUTPUT\n@@ -26,4 +26,4 @@\n --publish_to_big_query=true\n --metrics_dataset=beam_run_inference\n --metrics_table=tf_mnist_classification\n---runner=DataflowRunner\n\\ No newline at end of file\n+--runner=DataflowRunner\n@@ -26,4 +26,4 @@\n --publish_to_big_query=true\n --metrics_dataset=beam_run_inference\n --metrics_table=python_wordcount\n---runner=DataflowRunner\n\\ No newline at end of file\n+--runner=DataflowRunner\n@@ -94,4 +94,3 @@ jobs:\n         with:\n           name: pytest-${{matrix.os}}-${{matrix.params.py_ver}}\n           path: sdks/python/pytest**.xml\n-\n@@ -69,12 +69,12 @@ jobs:\n \n         echo \"------Checking Hash Value for apache_beam-${RELEASE}rc${{ github.event.inputs.RC }}.tar.gz-----\"\n         sha512sum -c \"apache_beam-${RELEASE}rc${{ github.event.inputs.RC }}.tar.gz.sha512\"\n-        \n+\n         for artifact in *.whl; do\n           echo \"----------Checking Hash Value for ${artifact} wheel-----------\"\n           sha512sum -c \"${artifact}.sha512\"\n         done\n-        \n+\n         echo \"===================Removing sha512 files=======================\"\n         rm $(ls | grep -i \".*.sha512$\")\n \n@@ -51,9 +51,9 @@ jobs:\n         RC_NUM: \"${{ github.event.inputs.RC }}\"\n         RC_VERSION: \"rc${{ github.event.inputs.RC }}\"\n       run: |\n-        \n+\n         echo \"Publish SDK docker images to Docker Hub.\"\n-        \n+\n         echo \"================Pull RC Containers from DockerHub===========\"\n         IMAGES=$(docker search apache/beam --format \"{{.Name}}\" --limit 100)\n         KNOWN_IMAGES=()\n@@ -64,7 +64,7 @@ jobs:\n             KNOWN_IMAGES+=( $IMAGE )\n           fi\n         done < <(echo \"${IMAGES}\")\n-        \n+\n         echo \"================Confirming Release and RC version===========\"\n         echo \"Publishing the following images:\"\n         # Sort by name for easy examination\n@@ -75,7 +75,7 @@ jobs:\n         for IMAGE in \"${KNOWN_IMAGES[@]}\"; do\n           # Perform a carbon copy of ${RC_VERSION} to dockerhub with a new tag as ${RELEASE}.\n           docker buildx imagetools create --tag \"${IMAGE}:${RELEASE}\" \"${IMAGE}:${RELEASE}${RC_VERSION}\"\n-      \n+\n           # Perform a carbon copy of ${RC_VERSION} to dockerhub with a new tag as latest.\n           docker buildx imagetools create --tag \"${IMAGE}:latest\" \"${IMAGE}:${RELEASE}\"\n         done\n@@ -142,14 +142,14 @@ jobs:\n       run: |\n         # Ensure local tags are in sync. If there's a mismatch, it will tell you.\n         git fetch --all --tags --prune\n-        \n+\n         # If the tag exists, a commit number is produced, otherwise there's an error.\n         git rev-list $RC_TAG -n 1\n-        \n+\n         # Tag for Go SDK\n         git tag \"sdks/$VERSION_TAG\" \"$RC_TAG\"^{} -m \"Tagging release\" --local-user=\"${{steps.import_gpg.outputs.name}}\"\n         git push https://github.com/apache/beam \"sdks/$VERSION_TAG\"\n-        \n+\n         # Tag for repo root.\n         git tag \"$VERSION_TAG\" \"$RC_TAG\"^{} -m \"Tagging release\" --local-user=\"${{steps.import_gpg.outputs.name}}\"\n         git push https://github.com/apache/beam \"$VERSION_TAG\"\n@@ -40,7 +40,7 @@ jobs:\n     steps:\n       - uses: actions/checkout@v4\n       - uses: actions/setup-python@v5\n-        with: \n+        with:\n           python-version: 3.11\n       - run: pip install PyGithub\n       - run: python .test-infra/tools/flaky_test_detection.py\n@@ -21,4 +21,4 @@\n --endpoint=localhost:8099\n --environment_type=DOCKER\n --environment_config=gcr.io/apache-beam-testing/beam-sdk/beam_go_sdk:latest\n---runner=FlinkRunner\n\\ No newline at end of file\n+--runner=FlinkRunner\n@@ -22,4 +22,4 @@\n --jobEndpoint=localhost:8099\n --defaultEnvironmentType=DOCKER\n --defaultEnvironmentConfig=gcr.io/apache-beam-testing/beam-sdk/beam_java11_sdk:latest\n---runner=FlinkRunner\n\\ No newline at end of file\n+--runner=FlinkRunner\n@@ -19,4 +19,4 @@\n --job_endpoint=localhost:8099\n --environment_type=DOCKER\n --top_count=10\n---runner=PortableRunner\n\\ No newline at end of file\n+--runner=PortableRunner\n@@ -50,5 +50,3 @@ jobs:\n         run: |\n           git tag -a ${{ github.event.inputs.VERSION_TAG }} -m ${{ github.event.inputs.RC_TAG }}\n           git push https://github.com/apache/beam ${{ github.event.inputs.VERSION_TAG }}\n-\n-\n@@ -53,14 +53,14 @@ jobs:\n         run: cd sdks && go test -timeout=25m -coverprofile=coverage.txt -covermode=atomic ./go/pkg/... ./go/container/... ./java/container/... ./python/container/... ./typescript/container/...\n       - uses: codecov/codecov-action@v3\n         with:\n-          flags: go \n+          flags: go\n           files: ./sdks/coverage.txt\n           name: go-unittests\n       - name: Run fmt\n         run: cd sdks/go/pkg/beam && go fmt ./...; git diff-index --quiet HEAD || (echo \"Run go fmt before checking in changes\" && exit 1)\n       - name: Run vet\n-        run: | \n-          cd sdks/go/pkg/beam \n+        run: |\n+          cd sdks/go/pkg/beam\n           go vet --copylocks=false --unsafeptr=false ./...\n       - name: Run Staticcheck\n         run: |\n@@ -20,7 +20,7 @@\n name: Java Tests\n on:\n   workflow_dispatch:\n-  \n+\n   schedule:\n     - cron: '10 2 * * *'\n   push:\n@@ -20,4 +20,4 @@\n --staging_location=gs://temp-storage-for-perf-tests/loadtests\n --temp_location=gs://temp-storage-for-perf-tests/loadtests\n --runner=DataflowRunner\n---requirements_file=apache_beam/testing/benchmarks/cloudml/requirements.txt\n\\ No newline at end of file\n+--requirements_file=apache_beam/testing/benchmarks/cloudml/requirements.txt\n@@ -31,4 +31,4 @@\n --device=CPU\n --input_file=gs://apache-beam-ml/testing/inputs/openimage_50k_benchmark.txt\n --model_state_dict_path=gs://apache-beam-ml/models/torchvision.models.resnet152.pth\n---runner=DataflowRunner\n\\ No newline at end of file\n+--runner=DataflowRunner\n@@ -31,4 +31,4 @@\n --input_file=gs://apache-beam-ml/testing/inputs/sentences_50k.txt\n --bert_tokenizer=bert-base-uncased\n --model_state_dict_path=gs://apache-beam-ml/models/huggingface.BertForMaskedLM.bert-base-uncased.pth\n---runner=DataflowRunner\n\\ No newline at end of file\n+--runner=DataflowRunner\n@@ -31,4 +31,4 @@\n --input_file=gs://apache-beam-ml/testing/inputs/sentences_50k.txt\n --bert_tokenizer=bert-large-uncased\n --model_state_dict_path=gs://apache-beam-ml/models/huggingface.BertForMaskedLM.bert-large-uncased.pth\n---runner=DataflowRunner\n\\ No newline at end of file\n+--runner=DataflowRunner"
  },
  "generation_timestamp": "2025-07-19T01:55:17.380967"
}